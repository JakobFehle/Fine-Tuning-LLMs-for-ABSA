{"model_name_or_path": "meta-llama/Meta-Llama-3-8B", "seed": 42, "model_task": "e2e", "model_shots": "", "model_prompt_style": "cot", "model_lang": "en", "model_quant": 4, "model_lr": 0.0003, "model_lora_alpha": 64, "model_lora_r": 32, "model_lora_dropout": 0.05, "quant": 16, "bf16": true, "fp16": false, "flash_attention": true, "run_tag": "", "epoch": 10, "dataset": "rest-16", "lang": "en", "shots": "", "prompt_style": "cot", "low_resource_setting": 1000, "split": 0, "wandb": true, "max_seq_length": 2048, "task": "e2e", "test": false, "api": false, "json": false, "original_split": false, "max_new_tokens": 300, "do_sample": false, "use_cache": true, "top_k": -1, "top_p": 1, "temperature": 0, "model_config": "en_rest-16__cot_e2e_0.0003_32_64_0.05_4_0_1000_meta-llama-Meta-Llama-3-8B", "results_model_config": "en_rest-16__cot_e2e_0.0003_32_64_0.05_4_0_1000_meta-llama-Meta-Llama-3-8B", "inference_tokens": 1074.424269687041, "inference_tokens_w_prompt": 2857.2850180175283}