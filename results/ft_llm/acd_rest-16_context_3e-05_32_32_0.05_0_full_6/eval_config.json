{"model_name_or_path": "meta-llama/Meta-Llama-3-8B", "seed": 42, "model_task": "acd", "model_shots": "", "model_prompt_style": "long", "model_lang": "en", "model_quant": 4, "model_lr": 3e-05, "model_lora_alpha": 32, "model_lora_r": 32, "model_lora_dropout": 0.05, "quant": 16, "bf16": true, "fp16": false, "flash_attention": true, "run_tag": "", "epoch": 10, "dataset": "rest-16", "lang": "en", "shots": "", "prompt_style": "long", "low_resource_setting": "full", "split": 0, "wandb": true, "max_seq_length": 2048, "task": "acd", "test": false, "api": false, "json": false, "original_split": false, "max_new_tokens": 300, "do_sample": false, "use_cache": true, "top_k": -1, "top_p": 1, "temperature": 0, "model_config": "en__long_acd_3e-05_32_32_0.05_4_0_full_meta-llama-Meta-Llama-3-8B", "results_model_config": "en_rest-16__long_acd_3e-05_32_32_0.05_4_0_full_meta-llama-Meta-Llama-3-8B", "eval_time": 29.20106267929077, "inference_tokens": 99.61966220027487, "inference_tokens_w_prompt": 3878.8999305949583}