{"model_name_or_path": "meta-llama/Meta-Llama-3-8B", "seed": 42, "model_task": "acsa", "model_shots": "", "model_prompt_style": "short", "model_lang": "en", "model_quant": 4, "model_lr": 0.0003, "model_lora_alpha": 64, "model_lora_r": 32, "model_lora_dropout": 0.05, "quant": 16, "bf16": true, "fp16": false, "flash_attention": true, "run_tag": "", "epoch": 10, "dataset": "rest-16", "lang": "en", "shots": "", "prompt_style": "short", "low_resource_setting": 500, "split": 0, "wandb": true, "max_seq_length": 2048, "task": "acsa", "test": false, "api": false, "json": false, "original_split": false, "max_new_tokens": 300, "do_sample": false, "use_cache": true, "top_k": -1, "top_p": 1, "temperature": 0, "model_config": "en_rest-16__short_acsa_0.0003_32_64_0.05_4_0_500_meta-llama-Meta-Llama-3-8B", "results_model_config": "en_rest-16__short_acsa_0.0003_32_64_0.05_4_0_500_meta-llama-Meta-Llama-3-8B", "eval_time": 4.594475269317627, "inference_tokens": 271.1952784512553, "inference_tokens_w_prompt": 3043.0025586091497}