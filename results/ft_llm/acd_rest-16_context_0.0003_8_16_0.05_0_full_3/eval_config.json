{"model_name_or_path": "meta-llama/Meta-Llama-3-8B", "seed": 42, "model_task": "acd", "model_shots": "", "model_prompt_style": "long", "model_lang": "en", "model_quant": 4, "model_lr": 0.0003, "model_lora_alpha": 16, "model_lora_r": 8, "model_lora_dropout": 0.05, "quant": 16, "bf16": true, "fp16": false, "flash_attention": true, "run_tag": "", "epoch": 10, "dataset": "rest-16", "lang": "en", "shots": "", "prompt_style": "long", "low_resource_setting": "full", "split": 0, "wandb": true, "max_seq_length": 2048, "task": "acd", "test": false, "api": false, "json": false, "original_split": false, "max_new_tokens": 300, "do_sample": false, "use_cache": true, "top_k": -1, "top_p": 1, "temperature": 0, "model_config": "en__long_acd_0.0003_8_16_0.05_4_0_full_meta-llama-Meta-Llama-3-8B", "results_model_config": "en_rest-16__long_acd_0.0003_8_16_0.05_4_0_full_meta-llama-Meta-Llama-3-8B", "eval_time": 39.54527282714844, "inference_tokens": 505.6735880267275, "inference_tokens_w_prompt": 3296.37376810582}