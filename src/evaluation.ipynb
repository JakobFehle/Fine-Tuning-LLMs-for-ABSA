{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af0f996-5a35-4be6-a321-8b71abb20223",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d37cb8-8aa3-4e75-8d27-60fe254e0b1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f188a97c-6c46-46b9-b193-6b4b156269e2",
   "metadata": {},
   "source": [
    "## Baseline Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618d18d-3ba5-4cc4-b342-d70ca6c6f04d",
   "metadata": {},
   "source": [
    "## ACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2daaf548-49eb-4039-b0dd-1691a84bcaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = 'mlcf'\n",
    "RESULTS_PATH = '../results_pp'\n",
    "\n",
    "col_names = ['task', 'dataset', 'lr-setting', 'split', 'learning-rate', 'batch_size', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']\n",
    "folder_names = [folder for folder in os.listdir(os.path.join(RESULTS_PATH, METHOD)) if os.path.isdir(os.path.join(RESULTS_PATH, METHOD, folder)) and folder != '.ipynb_checkpoints']\n",
    "runs = []\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(RESULTS_PATH, METHOD, folder_name, 'metrics_asp.tsv'), sep = '\\t')\n",
    "        df = df.set_index(df.columns[0])\n",
    "        cond_name = folder_name.split('/')[-1]\n",
    "        cond_parameters = cond_name.split('_')\n",
    "        \n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Macro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'accuracy'])\n",
    "        runs.append(cond_parameters)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "results_all = pd.DataFrame(runs, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "42208a0d-7639-416e-90eb-a7f07d2fff8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>0.8807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0.8717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>0.8712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>0.8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9291</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.8677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.8668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.8658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9191</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "35   GERestaurant  acd         4e-05          8          0      6    0.9366   \n",
       "39   GERestaurant  acd         3e-05         32          0      3    0.9350   \n",
       "91   GERestaurant  acd         3e-05         32          0      2    0.9315   \n",
       "63   GERestaurant  acd         2e-05         32          0      2    0.9312   \n",
       "140  GERestaurant  acd         2e-05          8          0      6    0.9311   \n",
       "324  GERestaurant  acd         1e-05         32          0      4    0.9300   \n",
       "41   GERestaurant  acd         3e-05          8          0      5    0.9291   \n",
       "318  GERestaurant  acd         3e-05          8          0      2    0.9287   \n",
       "85   GERestaurant  acd         4e-05         16          0      3    0.9280   \n",
       "37   GERestaurant  acd         1e-05         32          0      3    0.9279   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "35     0.9261    0.8807  \n",
       "39     0.9276    0.8780  \n",
       "91     0.9229    0.8717  \n",
       "63     0.9233    0.8712  \n",
       "140    0.9232    0.8710  \n",
       "324    0.9241    0.8691  \n",
       "41     0.9162    0.8677  \n",
       "318    0.9226    0.8668  \n",
       "85     0.9141    0.8658  \n",
       "37     0.9191    0.8655  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acd'\n",
    "split = '0'\n",
    "lr_setting = '0'\n",
    "\n",
    "####\n",
    "\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1dc9bc55-135d-465d-b8e5-f6e5992a168c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.8774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9323</td>\n",
       "      <td>0.9236</td>\n",
       "      <td>0.8732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.8704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.8685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9293</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>0.8679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.8651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.8611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.8605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "336  GERestaurant  acd         4e-05         32       1000      4    0.9347   \n",
       "315  GERestaurant  acd         1e-05          8       1000      7    0.9343   \n",
       "167  GERestaurant  acd         1e-05          8       1000      3    0.9333   \n",
       "314  GERestaurant  acd         5e-05         16       1000      6    0.9323   \n",
       "224  GERestaurant  acd         2e-05          8       1000      4    0.9307   \n",
       "144  GERestaurant  acd         4e-05          8       1000      7    0.9296   \n",
       "254  GERestaurant  acd         1e-05         32       1000      3    0.9293   \n",
       "48   GERestaurant  acd         2e-05         32       1000      6    0.9277   \n",
       "32   GERestaurant  acd         6e-05         32       1000      6    0.9254   \n",
       "30   GERestaurant  acd         5e-05         32       1000      5    0.9250   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "336    0.9269    0.8774  \n",
       "315    0.9307    0.8768  \n",
       "167    0.9262    0.8750  \n",
       "314    0.9236    0.8732  \n",
       "224    0.9200    0.8704  \n",
       "144    0.9210    0.8685  \n",
       "254    0.9274    0.8679  \n",
       "48     0.9193    0.8651  \n",
       "32     0.9187    0.8611  \n",
       "30     0.9158    0.8605  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acd'\n",
    "split = '0'\n",
    "lr_setting = '1000'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3c03d36-db30-439f-ac37-1240ce026ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.8807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.9013</td>\n",
       "      <td>0.8319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.9013</td>\n",
       "      <td>0.8319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.8230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.8230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.8230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.8230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.8230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.8230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "388  GERestaurant  acd         2e-05          8        500      5    0.9366   \n",
       "43   GERestaurant  acd         3e-05          8        500      3    0.9091   \n",
       "102  GERestaurant  acd         1e-05         32        500      2    0.9082   \n",
       "335  GERestaurant  acd         5e-05         16        500      3    0.9082   \n",
       "23   GERestaurant  acd         4e-05          8        500      3    0.9029   \n",
       "175  GERestaurant  acd         2e-05          8        500      3    0.9029   \n",
       "146  GERestaurant  acd         6e-05          8        500      3    0.9029   \n",
       "454  GERestaurant  acd         2e-05          8        500      2    0.9029   \n",
       "303  GERestaurant  acd         4e-05          8        500      4    0.9029   \n",
       "258  GERestaurant  acd         5e-05          8        500      7    0.9029   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "388    0.9307    0.8807  \n",
       "43     0.8986    0.8333  \n",
       "102    0.9013    0.8319  \n",
       "335    0.9013    0.8319  \n",
       "23     0.8951    0.8230  \n",
       "175    0.8951    0.8230  \n",
       "146    0.8951    0.8230  \n",
       "454    0.8951    0.8230  \n",
       "303    0.8951    0.8230  \n",
       "258    0.8951    0.8230  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acd'\n",
    "split = '0'\n",
    "lr_setting = '500'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "050bd1dc-98a1-47a2-b985-8762a93d4529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8289</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>0.7078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8183</td>\n",
       "      <td>0.7218</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8171</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.6907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.7265</td>\n",
       "      <td>0.6892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.7017</td>\n",
       "      <td>0.6839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.6829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8114</td>\n",
       "      <td>0.7288</td>\n",
       "      <td>0.6827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8109</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8104</td>\n",
       "      <td>0.7257</td>\n",
       "      <td>0.6813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.7231</td>\n",
       "      <td>0.6806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "260  rest-16  acd         4e-05         32          0      5    0.8289   \n",
       "27   rest-16  acd         4e-05          8          0      5    0.8183   \n",
       "56   rest-16  acd         4e-05          8          0      3    0.8171   \n",
       "361  rest-16  acd         1e-05         16          0      2    0.8160   \n",
       "125  rest-16  acd         3e-05         16          0      5    0.8122   \n",
       "120  rest-16  acd         6e-05         32          0      5    0.8116   \n",
       "196  rest-16  acd         2e-05         32          0      4    0.8114   \n",
       "214  rest-16  acd         2e-05         32          0      3    0.8109   \n",
       "373  rest-16  acd         4e-05         32          0      3    0.8104   \n",
       "275  rest-16  acd         3e-05         32          0      5    0.8100   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "260    0.7458    0.7078  \n",
       "27     0.7218    0.6925  \n",
       "56     0.7271    0.6907  \n",
       "361    0.7265    0.6892  \n",
       "125    0.7017    0.6839  \n",
       "120    0.7101    0.6829  \n",
       "196    0.7288    0.6827  \n",
       "214    0.7051    0.6819  \n",
       "373    0.7257    0.6813  \n",
       "275    0.7231    0.6806  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'rest-16'\n",
    "task = 'acd'\n",
    "split = '0'\n",
    "lr_setting = '0'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa81d84d-2ac4-4915-a697-798f949910c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7911</td>\n",
       "      <td>0.6916</td>\n",
       "      <td>0.6544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>0.6506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.6642</td>\n",
       "      <td>0.6504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.7009</td>\n",
       "      <td>0.6447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7822</td>\n",
       "      <td>0.6785</td>\n",
       "      <td>0.6423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7802</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.6367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.7006</td>\n",
       "      <td>0.6367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7743</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.6318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7743</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.6318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "349  rest-16  acd         6e-05          8       1000      6    0.7911   \n",
       "121  rest-16  acd         4e-05         32       1000      5    0.7883   \n",
       "232  rest-16  acd         1e-05          8       1000      3    0.7881   \n",
       "219  rest-16  acd         3e-05         32       1000      5    0.7840   \n",
       "169  rest-16  acd         6e-05         16       1000      2    0.7822   \n",
       "446  rest-16  acd         1e-05          8       1000      2    0.7802   \n",
       "328  rest-16  acd         6e-05          8       1000      2    0.7780   \n",
       "439  rest-16  acd         2e-05         32       1000      3    0.7780   \n",
       "449  rest-16  acd         2e-05         32       1000      5    0.7743   \n",
       "370  rest-16  acd         2e-05         32       1000      6    0.7743   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "349    0.6916    0.6544  \n",
       "121    0.7089    0.6506  \n",
       "232    0.6642    0.6504  \n",
       "219    0.7009    0.6447  \n",
       "169    0.6785    0.6423  \n",
       "446    0.6525    0.6397  \n",
       "328    0.6780    0.6367  \n",
       "439    0.7006    0.6367  \n",
       "449    0.6486    0.6318  \n",
       "370    0.6738    0.6318  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'rest-16'\n",
    "task = 'acd'\n",
    "split = '0'\n",
    "lr_setting = '1000'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1b6a22ba-a66c-41d4-bbdb-671774336f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.5090</td>\n",
       "      <td>0.5253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.4461</td>\n",
       "      <td>0.5226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6844</td>\n",
       "      <td>0.4325</td>\n",
       "      <td>0.5203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6822</td>\n",
       "      <td>0.5069</td>\n",
       "      <td>0.5176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6816</td>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>0.4221</td>\n",
       "      <td>0.5159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>0.4212</td>\n",
       "      <td>0.5159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>0.5091</td>\n",
       "      <td>0.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acd</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6781</td>\n",
       "      <td>0.4686</td>\n",
       "      <td>0.5130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "400  rest-16  acd         6e-05         32        500      3    0.6888   \n",
       "351  rest-16  acd         6e-05         32        500      7    0.6864   \n",
       "168  rest-16  acd         1e-05         32        500      5    0.6844   \n",
       "67   rest-16  acd         2e-05          8        500      2    0.6822   \n",
       "105  rest-16  acd         6e-05         16        500      7    0.6816   \n",
       "383  rest-16  acd         2e-05          8        500      7    0.6806   \n",
       "376  rest-16  acd         1e-05         32        500      4    0.6806   \n",
       "157  rest-16  acd         4e-05         32        500      5    0.6804   \n",
       "213  rest-16  acd         6e-05         32        500      5    0.6804   \n",
       "450  rest-16  acd         3e-05          8        500      2    0.6781   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "400    0.5090    0.5253  \n",
       "351    0.4461    0.5226  \n",
       "168    0.4325    0.5203  \n",
       "67     0.5069    0.5176  \n",
       "105    0.4094    0.5170  \n",
       "383    0.4221    0.5159  \n",
       "376    0.4212    0.5159  \n",
       "157    0.4492    0.5155  \n",
       "213    0.5091    0.5155  \n",
       "450    0.4686    0.5130  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'rest-16'\n",
    "task = 'acd'\n",
    "split = '0'\n",
    "lr_setting = '500'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396fa1f-8d4e-4e09-9526-943ca3779cfc",
   "metadata": {},
   "source": [
    "## ACSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "062e5bef-79ad-46a6-a4ee-4b759d7c0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = 'mlcf'\n",
    "RESULTS_PATH = '../results_pp'\n",
    "\n",
    "# col_names = ['task', 'dataset', 'lr-setting', 'split', 'learning-rate', 'batch_size', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']\n",
    "col_names = ['task', 'dataset', 'lr-setting', 'split', 'learning-rate', 'batch_size', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']\n",
    "folder_names = [folder for folder in os.listdir(os.path.join(RESULTS_PATH, METHOD)) if os.path.isdir(os.path.join(RESULTS_PATH, METHOD, folder)) and folder != '.ipynb_checkpoints']\n",
    "runs = []\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(RESULTS_PATH, METHOD, folder_name, 'metrics_asp_pol.tsv'), sep = '\\t')\n",
    "        df = df.set_index(df.columns[0])\n",
    "        cond_name = folder_name.split('/')[-1]\n",
    "        cond_parameters = cond_name.split('_')\n",
    "        \n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Macro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'accuracy'])\n",
    "        runs.append(cond_parameters)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "results_all = pd.DataFrame(runs, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4014848-912b-4c7a-9d68-dd8bf41319ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9095</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>0.8306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9054</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>0.8272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9039</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.8247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9021</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.8216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9019</td>\n",
       "      <td>0.8982</td>\n",
       "      <td>0.8214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9006</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "188  GERestaurant  acsa         2e-05         32          0      6    0.9095   \n",
       "106  GERestaurant  acsa         1e-05          8          0      7    0.9074   \n",
       "64   GERestaurant  acsa         4e-05         16          0      5    0.9054   \n",
       "173  GERestaurant  acsa         1e-05         32          0      4    0.9047   \n",
       "15   GERestaurant  acsa         3e-05         16          0      3    0.9047   \n",
       "244  GERestaurant  acsa         4e-05         32          0      6    0.9039   \n",
       "141  GERestaurant  acsa         2e-05         16          0      7    0.9021   \n",
       "124  GERestaurant  acsa         2e-05         32          0      5    0.9019   \n",
       "44   GERestaurant  acsa         6e-05          8          0      5    0.9011   \n",
       "170  GERestaurant  acsa         2e-05         32          0      4    0.9006   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "188    0.9068    0.8340  \n",
       "106    0.9051    0.8306  \n",
       "64     0.9043    0.8272  \n",
       "173    0.8960    0.8261  \n",
       "15     0.8957    0.8261  \n",
       "244    0.9024    0.8247  \n",
       "141    0.8985    0.8216  \n",
       "124    0.8982    0.8214  \n",
       "44     0.8899    0.8200  \n",
       "170    0.8936    0.8193  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acsa'\n",
    "split = '0'\n",
    "lr_setting = '0'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97bb93a5-8654-4498-9137-37bf4c2f7b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9069</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.8296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.8679</td>\n",
       "      <td>0.8161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.8089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.8580</td>\n",
       "      <td>0.8044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.7948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>0.7931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>0.7841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8781</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>0.7826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0.8482</td>\n",
       "      <td>0.7763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "63   GERestaurant  acsa         5e-05         32       1000      7    0.9069   \n",
       "67   GERestaurant  acsa         1e-05          8       1000      3    0.8988   \n",
       "179  GERestaurant  acsa         3e-05         16       1000      3    0.8944   \n",
       "232  GERestaurant  acsa         4e-05         16       1000      7    0.8927   \n",
       "107  GERestaurant  acsa         5e-05          8       1000      5    0.8916   \n",
       "77   GERestaurant  acsa         5e-05         32       1000      5    0.8857   \n",
       "71   GERestaurant  acsa         5e-05          8       1000      6    0.8846   \n",
       "208  GERestaurant  acsa         3e-05         32       1000      7    0.8790   \n",
       "108  GERestaurant  acsa         6e-05         32       1000      6    0.8781   \n",
       "58   GERestaurant  acsa         4e-05         16       1000      4    0.8741   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "63     0.8730    0.8296  \n",
       "67     0.8679    0.8161  \n",
       "179    0.8585    0.8089  \n",
       "232    0.8674    0.8062  \n",
       "107    0.8580    0.8044  \n",
       "77     0.8680    0.7948  \n",
       "71     0.8630    0.7931  \n",
       "208    0.8627    0.7841  \n",
       "108    0.8564    0.7826  \n",
       "58     0.8482    0.7763  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acsa'\n",
    "split = '0'\n",
    "lr_setting = '1000'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "307f1e01-d0e6-496a-9477-b32952b3b847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>0.7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>0.7304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.7707</td>\n",
       "      <td>0.7304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8365</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.7190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8349</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.7167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>0.7073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.7059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>0.7049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>0.7049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "196  GERestaurant  acsa         1e-05         32        500      3    0.8488   \n",
       "186  GERestaurant  acsa         5e-05         32        500      7    0.8442   \n",
       "115  GERestaurant  acsa         1e-05         16        500      7    0.8442   \n",
       "229  GERestaurant  acsa         6e-05         16        500      6    0.8390   \n",
       "133  GERestaurant  acsa         4e-05         16        500      4    0.8365   \n",
       "195  GERestaurant  acsa         1e-05         16        500      4    0.8349   \n",
       "130  GERestaurant  acsa         4e-05         32        500      6    0.8286   \n",
       "172  GERestaurant  acsa         4e-05         16        500      5    0.8276   \n",
       "181  GERestaurant  acsa         3e-05          8        500      3    0.8269   \n",
       "8    GERestaurant  acsa         1e-05         16        500      2    0.8269   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "196    0.8218    0.7373  \n",
       "186    0.7352    0.7304  \n",
       "115    0.7707    0.7304  \n",
       "229    0.8020    0.7227  \n",
       "133    0.8193    0.7190  \n",
       "195    0.7929    0.7167  \n",
       "130    0.7812    0.7073  \n",
       "172    0.7972    0.7059  \n",
       "181    0.7955    0.7049  \n",
       "8      0.7904    0.7049  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acsa'\n",
    "split = '0'\n",
    "lr_setting = '500'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b92fb984-0ece-4c28-b3e4-43684e0e471e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7372</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.5839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.6306</td>\n",
       "      <td>0.5732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.5729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>0.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.6269</td>\n",
       "      <td>0.5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.5690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>0.5626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7187</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.5610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>0.5604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.6197</td>\n",
       "      <td>0.5600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "62   rest-16  acsa         5e-05          8          0      6    0.7372   \n",
       "120  rest-16  acsa         5e-05         32          0      7    0.7287   \n",
       "4    rest-16  acsa         1e-05         32          0      6    0.7285   \n",
       "145  rest-16  acsa         1e-05         16          0      3    0.7273   \n",
       "19   rest-16  acsa         1e-05         32          0      3    0.7256   \n",
       "112  rest-16  acsa         5e-05         16          0      7    0.7253   \n",
       "140  rest-16  acsa         3e-05          8          0      7    0.7201   \n",
       "224  rest-16  acsa         1e-05         32          0      2    0.7187   \n",
       "150  rest-16  acsa         3e-05         32          0      6    0.7183   \n",
       "164  rest-16  acsa         4e-05          8          0      3    0.7179   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "62     0.6243    0.5839  \n",
       "120    0.6306    0.5732  \n",
       "4      0.6440    0.5729  \n",
       "145    0.6098    0.5714  \n",
       "19     0.6269    0.5694  \n",
       "112    0.6450    0.5690  \n",
       "140    0.6091    0.5626  \n",
       "224    0.6216    0.5610  \n",
       "150    0.6263    0.5604  \n",
       "164    0.6197    0.5600  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'rest-16'\n",
    "task = 'acsa'\n",
    "split = '0'\n",
    "lr_setting = '0'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2a3f5a39-9246-43ca-8db4-568ae9af70e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.5507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7031</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.5507</td>\n",
       "      <td>0.5153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.5147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.5114</td>\n",
       "      <td>0.5120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6753</td>\n",
       "      <td>0.5221</td>\n",
       "      <td>0.5098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>0.5259</td>\n",
       "      <td>0.5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.6002</td>\n",
       "      <td>0.5080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>0.5271</td>\n",
       "      <td>0.5033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.5017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "128  rest-16  acsa         6e-05         16       1000      6    0.7103   \n",
       "9    rest-16  acsa         5e-05          8       1000      5    0.7031   \n",
       "123  rest-16  acsa         2e-05         16       1000      6    0.6801   \n",
       "39   rest-16  acsa         5e-05          8       1000      3    0.6796   \n",
       "182  rest-16  acsa         6e-05         16       1000      3    0.6773   \n",
       "113  rest-16  acsa         5e-05          8       1000      6    0.6753   \n",
       "206  rest-16  acsa         6e-05         16       1000      7    0.6739   \n",
       "42   rest-16  acsa         2e-05          8       1000      5    0.6737   \n",
       "51   rest-16  acsa         1e-05         16       1000      4    0.6696   \n",
       "73   rest-16  acsa         5e-05         16       1000      5    0.6682   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "128    0.5154    0.5507  \n",
       "9      0.5225    0.5421  \n",
       "123    0.5507    0.5153  \n",
       "39     0.5677    0.5147  \n",
       "182    0.5114    0.5120  \n",
       "113    0.5221    0.5098  \n",
       "206    0.5259    0.5082  \n",
       "42     0.6002    0.5080  \n",
       "51     0.5271    0.5033  \n",
       "73     0.5299    0.5017  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'rest-16'\n",
    "task = 'acsa'\n",
    "split = '0'\n",
    "lr_setting = '1000'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a8d7758a-9f43-43e2-9876-b26faa85e06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.4369</td>\n",
       "      <td>0.4720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.4363</td>\n",
       "      <td>0.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>6e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6148</td>\n",
       "      <td>0.4419</td>\n",
       "      <td>0.4438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>0.4345</td>\n",
       "      <td>0.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6109</td>\n",
       "      <td>0.4224</td>\n",
       "      <td>0.4398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6083</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.4371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>0.3328</td>\n",
       "      <td>0.4362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6051</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.4337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsa</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.4127</td>\n",
       "      <td>0.4327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "230  rest-16  acsa         2e-05          8        500      5    0.6414   \n",
       "41   rest-16  acsa         1e-05         16        500      4    0.6207   \n",
       "69   rest-16  acsa         6e-05         16        500      3    0.6148   \n",
       "49   rest-16  acsa         5e-05         16        500      5    0.6121   \n",
       "225  rest-16  acsa         2e-05          8        500      3    0.6121   \n",
       "68   rest-16  acsa         5e-05          8        500      3    0.6109   \n",
       "23   rest-16  acsa         3e-05         16        500      5    0.6083   \n",
       "222  rest-16  acsa         3e-05         32        500      6    0.6075   \n",
       "10   rest-16  acsa         3e-05          8        500      2    0.6051   \n",
       "178  rest-16  acsa         1e-05          8        500      2    0.6041   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "230    0.4369    0.4720  \n",
       "41     0.4363    0.4500  \n",
       "69     0.4419    0.4438  \n",
       "49     0.4345    0.4410  \n",
       "225    0.4150    0.4410  \n",
       "68     0.4224    0.4398  \n",
       "23     0.3928    0.4371  \n",
       "222    0.3328    0.4362  \n",
       "10     0.4270    0.4337  \n",
       "178    0.4127    0.4327  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'rest-16'\n",
    "task = 'acsa'\n",
    "split = '0'\n",
    "lr_setting = '500'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd517dc1-575c-4302-b649-a66a39700af9",
   "metadata": {},
   "source": [
    "## ACSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a805cd29-43b9-464c-af8a-52173e54858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = 't5'\n",
    "RESULTS_PATH = '../results_pp'\n",
    "\n",
    "# col_names = ['task', 'dataset', 'lr-setting', 'split', 'learning-rate', 'batch_size', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']\n",
    "col_names = ['dataset', 'task', 'lr-setting', 'split', 'learning-rate', 'batch_size', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']\n",
    "folder_names = [folder for folder in os.listdir(os.path.join(RESULTS_PATH, METHOD)) if os.path.isdir(os.path.join(RESULTS_PATH, METHOD, folder)) and folder != '.ipynb_checkpoints']\n",
    "runs = []\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(RESULTS_PATH, METHOD, folder_name, 'metrics_phrases.tsv'), sep = '\\t')\n",
    "        df = df.set_index(df.columns[0])\n",
    "        cond_name = folder_name.split('/')[-1]\n",
    "        cond_parameters = cond_name.split('_')\n",
    "        \n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Macro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'accuracy'])\n",
    "        runs.append(cond_parameters)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "results_all = pd.DataFrame(runs, columns = col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3035f16b-f232-4852-81a1-eb8b697b9a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>3.6055e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7817</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>0.6417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>3.1691e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7604</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.6135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>6.6504e-05</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.7561</td>\n",
       "      <td>0.7313</td>\n",
       "      <td>0.6078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>3.459e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000119088</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.6012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000144559</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.7261</td>\n",
       "      <td>0.5975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>3.0473e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.5929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000113753</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7434</td>\n",
       "      <td>0.7264</td>\n",
       "      <td>0.5916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>4.8363e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.5913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>2.2212e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>0.5901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000159282</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.5901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>4.9067e-05</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.7171</td>\n",
       "      <td>0.5894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>6.4805e-05</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>0.7189</td>\n",
       "      <td>0.5877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>9.3484e-05</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.7235</td>\n",
       "      <td>0.5854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000196107</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.5845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "230  GERestaurant  acsd    3.6055e-05         32          0     23    0.7817   \n",
       "28   GERestaurant  acsd    3.1691e-05         32          0     22    0.7604   \n",
       "242  GERestaurant  acsd    6.6504e-05         64          0     18    0.7561   \n",
       "47   GERestaurant  acsd     3.459e-05         32          0     24    0.7551   \n",
       "302  GERestaurant  acsd   0.000119088         32          0     24    0.7510   \n",
       "119  GERestaurant  acsd   0.000144559        128          0     17    0.7480   \n",
       "318  GERestaurant  acsd    3.0473e-05         32          0     22    0.7444   \n",
       "106  GERestaurant  acsd   0.000113753         32          0     23    0.7434   \n",
       "18   GERestaurant  acsd    4.8363e-05         32          0     18    0.7432   \n",
       "73   GERestaurant  acsd    2.2212e-05         32          0     24    0.7422   \n",
       "60   GERestaurant  acsd   0.000159282        128          0     16    0.7422   \n",
       "169  GERestaurant  acsd    4.9067e-05         64          0     18    0.7417   \n",
       "39   GERestaurant  acsd    6.4805e-05         64          0     18    0.7403   \n",
       "52   GERestaurant  acsd    9.3484e-05        128          0     15    0.7385   \n",
       "241  GERestaurant  acsd   0.000196107         32          0     23    0.7378   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "230    0.7640    0.6417  \n",
       "28     0.7456    0.6135  \n",
       "242    0.7313    0.6078  \n",
       "47     0.7331    0.6065  \n",
       "302    0.7347    0.6012  \n",
       "119    0.7261    0.5975  \n",
       "318    0.7217    0.5929  \n",
       "106    0.7264    0.5916  \n",
       "18     0.7225    0.5913  \n",
       "73     0.7186    0.5901  \n",
       "60     0.7286    0.5901  \n",
       "169    0.7171    0.5894  \n",
       "39     0.7189    0.5877  \n",
       "52     0.7235    0.5854  \n",
       "241    0.7167    0.5845  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acsd'\n",
    "split = '0'\n",
    "lr_setting = '0'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "print(len(results_sub))\n",
    "results_sub.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7051df9e-7087-4f93-81cb-2c5128ed0fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000188781</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7588</td>\n",
       "      <td>0.7334</td>\n",
       "      <td>0.6113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>9.6846e-05</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>0.6960</td>\n",
       "      <td>0.5868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000130461</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7369</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>0.5833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000219408</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.7208</td>\n",
       "      <td>0.5799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000192471</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>0.7091</td>\n",
       "      <td>0.5744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "218  GERestaurant  acsd   0.000188781         64       1000     24    0.7588   \n",
       "31   GERestaurant  acsd    9.6846e-05         64       1000     17    0.7396   \n",
       "130  GERestaurant  acsd   0.000130461         64       1000     22    0.7369   \n",
       "273  GERestaurant  acsd   0.000219408         64       1000     23    0.7340   \n",
       "266  GERestaurant  acsd   0.000192471         64       1000     22    0.7297   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "218    0.7334    0.6113  \n",
       "31     0.6960    0.5868  \n",
       "130    0.6873    0.5833  \n",
       "273    0.7208    0.5799  \n",
       "266    0.7091    0.5744  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acsd'\n",
    "split = '0'\n",
    "lr_setting = '1000'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "print(len(results_sub))\n",
    "results_sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3dc245f-226e-49b2-8a12-103924850a47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>8.9161e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>23</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000266506</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.6222</td>\n",
       "      <td>0.5203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000158868</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>23</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>0.5200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000215663</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.6676</td>\n",
       "      <td>0.5163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000193639</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "      <td>23</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.5064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "143  GERestaurant  acsd    8.9161e-05         32        500     23    0.6900   \n",
       "22   GERestaurant  acsd   0.000266506         32        500     20    0.6845   \n",
       "71   GERestaurant  acsd   0.000158868         32        500     23    0.6842   \n",
       "13   GERestaurant  acsd   0.000215663         32        500     20    0.6810   \n",
       "240  GERestaurant  acsd   0.000193639         32        500     23    0.6723   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "143    0.6550    0.5267  \n",
       "22     0.6222    0.5203  \n",
       "71     0.6745    0.5200  \n",
       "13     0.6676    0.5163  \n",
       "240    0.6433    0.5064  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acsd'\n",
    "split = '0'\n",
    "lr_setting = '500'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "print(len(results_sub))\n",
    "results_sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "532b0b1c-a751-497d-8639-b796f3add912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>3.1374e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.7668</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.6219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>6.7945e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7623</td>\n",
       "      <td>0.6988</td>\n",
       "      <td>0.6158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>6.3104e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.7598</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.6126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000106492</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7594</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>0.6122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>5.9086e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.6838</td>\n",
       "      <td>0.6065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "124  rest-16  acsd    3.1374e-05         32          0     25    0.7668   \n",
       "205  rest-16  acsd    6.7945e-05         32          0     16    0.7623   \n",
       "312  rest-16  acsd    6.3104e-05         32          0     18    0.7598   \n",
       "72   rest-16  acsd   0.000106492         32          0     22    0.7594   \n",
       "245  rest-16  acsd    5.9086e-05         32          0     16    0.7550   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "124    0.6962    0.6219  \n",
       "205    0.6988    0.6158  \n",
       "312    0.6720    0.6126  \n",
       "72     0.6806    0.6122  \n",
       "245    0.6838    0.6065  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'rest-16'\n",
    "task = 'acsd'\n",
    "split = '0'\n",
    "lr_setting = '0'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "print(len(results_sub))\n",
    "results_sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e6df4b7-4f67-40f8-b323-a625c010e9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>6.2974e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7254</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>0.5691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>5.12e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.5637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>5.6652e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.6669</td>\n",
       "      <td>0.5605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000140124</td>\n",
       "      <td>32</td>\n",
       "      <td>1000</td>\n",
       "      <td>23</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.5566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000138064</td>\n",
       "      <td>128</td>\n",
       "      <td>1000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7087</td>\n",
       "      <td>0.6195</td>\n",
       "      <td>0.5489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "231  rest-16  acsd    6.2974e-05         32       1000     23    0.7254   \n",
       "58   rest-16  acsd      5.12e-05         32       1000     23    0.7210   \n",
       "77   rest-16  acsd    5.6652e-05         32       1000     20    0.7184   \n",
       "114  rest-16  acsd   0.000140124         32       1000     23    0.7152   \n",
       "191  rest-16  acsd   0.000138064        128       1000     22    0.7087   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "231    0.6405    0.5691  \n",
       "58     0.6065    0.5637  \n",
       "77     0.6669    0.5605  \n",
       "114    0.6444    0.5566  \n",
       "191    0.6195    0.5489  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'rest-16'\n",
    "task = 'acsd'\n",
    "split = '0'\n",
    "lr_setting = '1000'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "print(len(results_sub))\n",
    "results_sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33a85131-7281-4864-81b9-b3953fdd1803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr-setting</th>\n",
       "      <th>epochs</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000224261</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>22</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.4593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000196165</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>22</td>\n",
       "      <td>0.6290</td>\n",
       "      <td>0.4972</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000149895</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>23</td>\n",
       "      <td>0.6136</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.4425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>5.4613e-05</td>\n",
       "      <td>64</td>\n",
       "      <td>500</td>\n",
       "      <td>24</td>\n",
       "      <td>0.6080</td>\n",
       "      <td>0.5139</td>\n",
       "      <td>0.4368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>rest-16</td>\n",
       "      <td>acsd</td>\n",
       "      <td>0.000313766</td>\n",
       "      <td>128</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6056</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.4343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  task learning-rate batch_size lr-setting epochs  f1-micro  \\\n",
       "317  rest-16  acsd   0.000224261        128        500     22    0.6295   \n",
       "2    rest-16  acsd   0.000196165        128        500     22    0.6290   \n",
       "43   rest-16  acsd   0.000149895        128        500     23    0.6136   \n",
       "61   rest-16  acsd    5.4613e-05         64        500     24    0.6080   \n",
       "238  rest-16  acsd   0.000313766        128        500     20    0.6056   \n",
       "\n",
       "     f1-macro  accuracy  \n",
       "317    0.4958    0.4593  \n",
       "2      0.4972    0.4588  \n",
       "43     0.4954    0.4425  \n",
       "61     0.5139    0.4368  \n",
       "238    0.4636    0.4343  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'rest-16'\n",
    "task = 'acsd'\n",
    "split = '0'\n",
    "lr_setting = '500'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr-setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['dataset', 'task', 'learning-rate', 'batch_size', 'lr-setting', 'epochs', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "print(len(results_sub))\n",
    "results_sub.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea132f-dc22-4aea-bae7-138473f3ec08",
   "metadata": {},
   "source": [
    "## PT & FT LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6ab31-c968-4ee7-94c8-0df1b5f378f6",
   "metadata": {},
   "source": [
    "### All Conditions and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5fb10aad-c4f9-4c8d-b8b6-6568c39d5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = '../results_final/'\n",
    "\n",
    "col_names = ['model_lang', 'dataset', 'model_shots', 'model_prompt', 'model_task', 'lr', 'lora_r', 'lora_alpha', 'lora_dropout', 'model_quant', 'split', 'lr_setting', 'model_name', 'lang', 'shots', 'prompt', 'task', 'quant', 'epoch', 'model_config', 'f1-micro', 'f1-macro', 'accuracy']\n",
    "folder_names = [folder for folder in os.listdir(RESULTS_PATH) if os.path.isdir(os.path.join(RESULTS_PATH, folder)) and folder != '.ipynb_checkpoints']\n",
    "runs = []\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    try:\n",
    "        df = pd.read_csv(RESULTS_PATH + folder_name + '/metrics_asp.tsv', sep = '\\t')\n",
    "        df = df.set_index(df.columns[0])\n",
    "        cond_name = folder_name.split('/')[-1]\n",
    "        cond_parameters = cond_name.split('_')\n",
    "\n",
    "        model_config = cond_parameters.copy()\n",
    "        # Remove split column from config string\n",
    "        model_config.pop(10)\n",
    "\n",
    "        # Remove epoch column from config string\n",
    "        model_config.pop(-1)\n",
    "        \n",
    "        cond_parameters.append('_'.join(model_config))\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Macro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'accuracy'])\n",
    "        runs.append(cond_parameters)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "results_all = pd.DataFrame(runs, columns = col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7bb3a0-5340-48c6-b5ea-8ebf79b35b25",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "271d6a47-aecf-4152-ab48-6d675d87fbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>prompt</th>\n",
       "      <th>lr</th>\n",
       "      <th>lora_r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>lora_dropout</th>\n",
       "      <th>split</th>\n",
       "      <th>lr_setting</th>\n",
       "      <th>model_name</th>\n",
       "      <th>epoch</th>\n",
       "      <th>model_config</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>4</td>\n",
       "      <td>en_GERestaurant__long_acd_0.0003_8_8_0.05_4_10...</td>\n",
       "      <td>0.9095</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>5</td>\n",
       "      <td>en_GERestaurant__long_acd_0.0003_8_8_0.05_4_10...</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>9</td>\n",
       "      <td>en_GERestaurant__short_acd_3e-05_32_64_0.05_4_...</td>\n",
       "      <td>0.9013</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.8204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>8</td>\n",
       "      <td>en_GERestaurant__long_acd_3e-05_32_64_0.05_4_1...</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>4</td>\n",
       "      <td>en_GERestaurant__short_acd_3e-05_32_32_0.05_4_...</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>0.8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__short_acd_3e-05_8_16_0.05_4_1...</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.8132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>5</td>\n",
       "      <td>en_GERestaurant__long_acd_3e-05_8_8_0.05_4_100...</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.8127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>8</td>\n",
       "      <td>en_GERestaurant__long_acd_0.0003_8_8_0.05_4_10...</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>0.8115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>9</td>\n",
       "      <td>en_GERestaurant__long_acd_3e-05_32_32_0.05_4_1...</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.8881</td>\n",
       "      <td>0.8110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__long_acd_3e-05_8_16_0.05_4_10...</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.8103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang       dataset task prompt      lr lora_r lora_alpha lora_dropout  \\\n",
       "1949   en  GERestaurant  acd   long  0.0003      8          8         0.05   \n",
       "692    en  GERestaurant  acd   long  0.0003      8          8         0.05   \n",
       "246    en  GERestaurant  acd  short   3e-05     32         64         0.05   \n",
       "2338   en  GERestaurant  acd   long   3e-05     32         64         0.05   \n",
       "3321   en  GERestaurant  acd  short   3e-05     32         32         0.05   \n",
       "3311   en  GERestaurant  acd  short   3e-05      8         16         0.05   \n",
       "2035   en  GERestaurant  acd   long   3e-05      8          8         0.05   \n",
       "1680   en  GERestaurant  acd   long  0.0003      8          8         0.05   \n",
       "1306   en  GERestaurant  acd   long   3e-05     32         32         0.05   \n",
       "2209   en  GERestaurant  acd   long   3e-05      8         16         0.05   \n",
       "\n",
       "     split lr_setting                  model_name epoch  \\\n",
       "1949     0       1000  meta-llama-Meta-Llama-3-8B     4   \n",
       "692      0       1000  meta-llama-Meta-Llama-3-8B     5   \n",
       "246      0       1000  meta-llama-Meta-Llama-3-8B     9   \n",
       "2338     0       1000  meta-llama-Meta-Llama-3-8B     8   \n",
       "3321     0       1000  meta-llama-Meta-Llama-3-8B     4   \n",
       "3311     0       1000  meta-llama-Meta-Llama-3-8B    10   \n",
       "2035     0       1000  meta-llama-Meta-Llama-3-8B     5   \n",
       "1680     0       1000  meta-llama-Meta-Llama-3-8B     8   \n",
       "1306     0       1000  meta-llama-Meta-Llama-3-8B     9   \n",
       "2209     0       1000  meta-llama-Meta-Llama-3-8B    10   \n",
       "\n",
       "                                           model_config  f1-micro  f1-macro  \\\n",
       "1949  en_GERestaurant__long_acd_0.0003_8_8_0.05_4_10...    0.9095    0.9012   \n",
       "692   en_GERestaurant__long_acd_0.0003_8_8_0.05_4_10...    0.9032    0.8947   \n",
       "246   en_GERestaurant__short_acd_3e-05_32_64_0.05_4_...    0.9013    0.9096   \n",
       "2338  en_GERestaurant__long_acd_3e-05_32_64_0.05_4_1...    0.9004    0.8936   \n",
       "3321  en_GERestaurant__short_acd_3e-05_32_32_0.05_4_...    0.9000    0.8972   \n",
       "3311  en_GERestaurant__short_acd_3e-05_8_16_0.05_4_1...    0.8970    0.8819   \n",
       "2035  en_GERestaurant__long_acd_3e-05_8_8_0.05_4_100...    0.8967    0.8909   \n",
       "1680  en_GERestaurant__long_acd_0.0003_8_8_0.05_4_10...    0.8960    0.9003   \n",
       "1306  en_GERestaurant__long_acd_3e-05_32_32_0.05_4_1...    0.8957    0.8881   \n",
       "2209  en_GERestaurant__long_acd_3e-05_8_16_0.05_4_10...    0.8952    0.8755   \n",
       "\n",
       "      accuracy  \n",
       "1949    0.8340  \n",
       "692     0.8235  \n",
       "246     0.8204  \n",
       "2338    0.8189  \n",
       "3321    0.8182  \n",
       "3311    0.8132  \n",
       "2035    0.8127  \n",
       "1680    0.8115  \n",
       "1306    0.8110  \n",
       "2209    0.8103  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acd'\n",
    "model = 'meta-llama-Meta-Llama-3-8B'\n",
    "split = '0'\n",
    "lr_setting = '1000'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['lr_setting'] == lr_setting, results_all['dataset'] == dataset, results_all['task'] == task, results_all['model_name'] == model, results_all['split'] == split])].sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_sub[['lang', 'dataset', 'task', 'prompt', 'lr', 'lora_r', 'lora_alpha', 'lora_dropout', 'split', 'lr_setting', 'model_name', 'epoch', 'model_config', 'f1-micro', 'f1-macro', 'accuracy']]\n",
    "results_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229935a-550c-4425-8184-a556f6302aeb",
   "metadata": {},
   "source": [
    "### Best Epoch per Condition\n",
    "\n",
    "Grouping results per best run per combination (only showing values from the best epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6c9e0ca1-a411-4947-8e43-e9741927d726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>prompt</th>\n",
       "      <th>lr</th>\n",
       "      <th>lora_r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>lora_dropout</th>\n",
       "      <th>split</th>\n",
       "      <th>lr_setting</th>\n",
       "      <th>model_name</th>\n",
       "      <th>epoch</th>\n",
       "      <th>model_config</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>4</td>\n",
       "      <td>en_GERestaurant__long_acd_0.0003_8_8_0.05_4_10...</td>\n",
       "      <td>0.9095</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>9</td>\n",
       "      <td>en_GERestaurant__short_acd_3e-05_32_64_0.05_4_...</td>\n",
       "      <td>0.9013</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.8204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>8</td>\n",
       "      <td>en_GERestaurant__long_acd_3e-05_32_64_0.05_4_1...</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>4</td>\n",
       "      <td>en_GERestaurant__short_acd_3e-05_32_32_0.05_4_...</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>0.8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__short_acd_3e-05_8_16_0.05_4_1...</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.8132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>5</td>\n",
       "      <td>en_GERestaurant__long_acd_3e-05_8_8_0.05_4_100...</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.8127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>9</td>\n",
       "      <td>en_GERestaurant__long_acd_3e-05_32_32_0.05_4_1...</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.8881</td>\n",
       "      <td>0.8110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__long_acd_3e-05_8_16_0.05_4_10...</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.8103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__long_acd_0.0003_32_32_0.05_4_...</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.8077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>5</td>\n",
       "      <td>en_GERestaurant__short_acd_0.0003_8_8_0.05_4_1...</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.8077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3693</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>6</td>\n",
       "      <td>en_GERestaurant__short_acd_0.0003_8_16_0.05_4_...</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.8063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>8</td>\n",
       "      <td>en_GERestaurant__short_acd_3e-05_8_8_0.05_4_10...</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>4</td>\n",
       "      <td>en_GERestaurant__long_acd_0.0003_8_16_0.05_4_1...</td>\n",
       "      <td>0.8834</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>0.7912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>4</td>\n",
       "      <td>en_GERestaurant__short_acd_0.0003_32_32_0.05_4...</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>0.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>short</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__short_acd_0.0003_32_64_0.05_4...</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.8539</td>\n",
       "      <td>0.7765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td>acd</td>\n",
       "      <td>long</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__long_acd_0.0003_32_64_0.05_4_...</td>\n",
       "      <td>0.8706</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>0.7708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang       dataset task prompt      lr lora_r lora_alpha lora_dropout  \\\n",
       "1949   en  GERestaurant  acd   long  0.0003      8          8         0.05   \n",
       "246    en  GERestaurant  acd  short   3e-05     32         64         0.05   \n",
       "2338   en  GERestaurant  acd   long   3e-05     32         64         0.05   \n",
       "3321   en  GERestaurant  acd  short   3e-05     32         32         0.05   \n",
       "3311   en  GERestaurant  acd  short   3e-05      8         16         0.05   \n",
       "2035   en  GERestaurant  acd   long   3e-05      8          8         0.05   \n",
       "1306   en  GERestaurant  acd   long   3e-05     32         32         0.05   \n",
       "2209   en  GERestaurant  acd   long   3e-05      8         16         0.05   \n",
       "2544   en  GERestaurant  acd   long  0.0003     32         32         0.05   \n",
       "1162   en  GERestaurant  acd  short  0.0003      8          8         0.05   \n",
       "3693   en  GERestaurant  acd  short  0.0003      8         16         0.05   \n",
       "1226   en  GERestaurant  acd  short   3e-05      8          8         0.05   \n",
       "1038   en  GERestaurant  acd   long  0.0003      8         16         0.05   \n",
       "503    en  GERestaurant  acd  short  0.0003     32         32         0.05   \n",
       "146    en  GERestaurant  acd  short  0.0003     32         64         0.05   \n",
       "135    en  GERestaurant  acd   long  0.0003     32         64         0.05   \n",
       "\n",
       "     split lr_setting                  model_name epoch  \\\n",
       "1949     0       1000  meta-llama-Meta-Llama-3-8B     4   \n",
       "246      0       1000  meta-llama-Meta-Llama-3-8B     9   \n",
       "2338     0       1000  meta-llama-Meta-Llama-3-8B     8   \n",
       "3321     0       1000  meta-llama-Meta-Llama-3-8B     4   \n",
       "3311     0       1000  meta-llama-Meta-Llama-3-8B    10   \n",
       "2035     0       1000  meta-llama-Meta-Llama-3-8B     5   \n",
       "1306     0       1000  meta-llama-Meta-Llama-3-8B     9   \n",
       "2209     0       1000  meta-llama-Meta-Llama-3-8B    10   \n",
       "2544     0       1000  meta-llama-Meta-Llama-3-8B     7   \n",
       "1162     0       1000  meta-llama-Meta-Llama-3-8B     5   \n",
       "3693     0       1000  meta-llama-Meta-Llama-3-8B     6   \n",
       "1226     0       1000  meta-llama-Meta-Llama-3-8B     8   \n",
       "1038     0       1000  meta-llama-Meta-Llama-3-8B     4   \n",
       "503      0       1000  meta-llama-Meta-Llama-3-8B     4   \n",
       "146      0       1000  meta-llama-Meta-Llama-3-8B     7   \n",
       "135      0       1000  meta-llama-Meta-Llama-3-8B     7   \n",
       "\n",
       "                                           model_config  f1-micro  f1-macro  \\\n",
       "1949  en_GERestaurant__long_acd_0.0003_8_8_0.05_4_10...    0.9095    0.9012   \n",
       "246   en_GERestaurant__short_acd_3e-05_32_64_0.05_4_...    0.9013    0.9096   \n",
       "2338  en_GERestaurant__long_acd_3e-05_32_64_0.05_4_1...    0.9004    0.8936   \n",
       "3321  en_GERestaurant__short_acd_3e-05_32_32_0.05_4_...    0.9000    0.8972   \n",
       "3311  en_GERestaurant__short_acd_3e-05_8_16_0.05_4_1...    0.8970    0.8819   \n",
       "2035  en_GERestaurant__long_acd_3e-05_8_8_0.05_4_100...    0.8967    0.8909   \n",
       "1306  en_GERestaurant__long_acd_3e-05_32_32_0.05_4_1...    0.8957    0.8881   \n",
       "2209  en_GERestaurant__long_acd_3e-05_8_16_0.05_4_10...    0.8952    0.8755   \n",
       "2544  en_GERestaurant__long_acd_0.0003_32_32_0.05_4_...    0.8936    0.8684   \n",
       "1162  en_GERestaurant__short_acd_0.0003_8_8_0.05_4_1...    0.8936    0.8837   \n",
       "3693  en_GERestaurant__short_acd_0.0003_8_16_0.05_4_...    0.8928    0.8723   \n",
       "1226  en_GERestaurant__short_acd_3e-05_8_8_0.05_4_10...    0.8889    0.8920   \n",
       "1038  en_GERestaurant__long_acd_0.0003_8_16_0.05_4_1...    0.8834    0.8747   \n",
       "503   en_GERestaurant__short_acd_0.0003_32_32_0.05_4...    0.8759    0.8713   \n",
       "146   en_GERestaurant__short_acd_0.0003_32_64_0.05_4...    0.8742    0.8539   \n",
       "135   en_GERestaurant__long_acd_0.0003_32_64_0.05_4_...    0.8706    0.8575   \n",
       "\n",
       "      accuracy  \n",
       "1949    0.8340  \n",
       "246     0.8204  \n",
       "2338    0.8189  \n",
       "3321    0.8182  \n",
       "3311    0.8132  \n",
       "2035    0.8127  \n",
       "1306    0.8110  \n",
       "2209    0.8103  \n",
       "2544    0.8077  \n",
       "1162    0.8077  \n",
       "3693    0.8063  \n",
       "1226    0.8000  \n",
       "1038    0.7912  \n",
       "503     0.7792  \n",
       "146     0.7765  \n",
       "135     0.7708  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_max = results_sub.groupby(['model_config'])['f1-micro'].idxmax()\n",
    "results_per_epoch = results_sub.loc[idx_max]\n",
    "print(len(results_per_epoch))\n",
    "\n",
    "# idx_max = results_per_epoch.groupby(['model_prompt', 'data_setting'])['f1-micro'].idxmax()\n",
    "# results_per_epoch = results_per_epoch.loc[idx_max]\n",
    "# print(len(results_per_epoch))\n",
    "\n",
    "display(results_per_epoch.sort_values(by = ['f1-micro'], ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b021deb6-8d1a-450c-80ee-b4c42fc4d6c7",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fdbabf6d-bba2-4929-9db4-74774773f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = '../results_final/'\n",
    "\n",
    "col_names = ['model_lang', 'dataset', 'model_shots', 'model_prompt', 'model_task', 'lr', 'lora_r', 'lora_alpha', 'lora_dropout', 'model_quant', 'split', 'lr_setting', 'model_name', 'lang', 'shots', 'prompt', 'task', 'quant', 'epoch', 'model_config', 'f1-micro', 'f1-macro', 'accuracy']\n",
    "folder_names = [folder for folder in os.listdir(RESULTS_PATH) if os.path.isdir(os.path.join(RESULTS_PATH, folder)) and folder != '.ipynb_checkpoints']\n",
    "runs = []\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    try:\n",
    "        df = pd.read_csv(RESULTS_PATH + folder_name + '/metrics_phrases.tsv', sep = '\\t')\n",
    "        df = df.set_index(df.columns[0])\n",
    "        cond_name = folder_name.split('/')[-1]\n",
    "        cond_parameters = cond_name.split('_')\n",
    "\n",
    "        model_config = cond_parameters.copy()\n",
    "        # Remove split column from config string\n",
    "        model_config.pop(10)\n",
    "\n",
    "        # Remove epoch column from config string\n",
    "        model_config.pop(-1)\n",
    "        \n",
    "        cond_parameters.append('_'.join(model_config))\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Macro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'accuracy'])\n",
    "        runs.append(cond_parameters)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "results_all = pd.DataFrame(runs, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "13bed836-5170-4bac-980f-334741a4993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### \n",
    "#   FILTER\n",
    "####\n",
    "\n",
    "dataset = 'GERestaurant'\n",
    "task = 'acsd'\n",
    "model = 'meta-llama-Meta-Llama-3-8B'\n",
    "lora_alpha = '16'\n",
    "lora_r = '8'\n",
    "lang = 'en'\n",
    "\n",
    "####\n",
    "\n",
    "# results_sub = results_all[np.logical_and.reduce([results_all['lora_alpha'] == '16', results_all['lora_r'] == '16', results_all['model_name'] == 'meta-llama-Meta-Llama-3-8B', results_all['task'] == 'acd'])].head(10).sort_values(by = ['f1-micro'], ascending = False)\n",
    "results_sub = results_all[np.logical_and.reduce([results_all['dataset'] == dataset, \n",
    "                                                 results_all['task'] == task, \n",
    "                                                 results_all['model_name'] == model,\n",
    "                                                 results_all['lora_alpha'] == lora_alpha,\n",
    "                                                 results_all['split'] != '0',\n",
    "                                                 results_all['lora_r'] == lora_r,\n",
    "                                                 results_all['model_lang'] == lang])].sort_values(by = ['f1-micro'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "35902e58-ab3a-46b4-9b5a-9d988809d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_lang</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_shots</th>\n",
       "      <th>model_prompt</th>\n",
       "      <th>model_task</th>\n",
       "      <th>lr</th>\n",
       "      <th>lora_r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>lora_dropout</th>\n",
       "      <th>model_quant</th>\n",
       "      <th>split</th>\n",
       "      <th>lr_setting</th>\n",
       "      <th>model_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>shots</th>\n",
       "      <th>prompt</th>\n",
       "      <th>task</th>\n",
       "      <th>quant</th>\n",
       "      <th>epoch</th>\n",
       "      <th>model_config</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>full</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.7658</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>full</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>0.6080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>full</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.6347</td>\n",
       "      <td>0.5996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>full</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.6361</td>\n",
       "      <td>0.5952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>full</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.6159</td>\n",
       "      <td>0.5781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.5065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.5679</td>\n",
       "      <td>0.4921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.6492</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.4806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>0.4705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.6383</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.4688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.5729</td>\n",
       "      <td>0.3874</td>\n",
       "      <td>0.4014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.5722</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>0.4007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.5696</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.3983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>0.5021</td>\n",
       "      <td>0.3851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.3710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_lang       dataset model_shots model_prompt model_task     lr  \\\n",
       "67          en  GERestaurant                    short       acsd  1e-05   \n",
       "154         en  GERestaurant                    short       acsd  1e-05   \n",
       "69          en  GERestaurant                    short       acsd  1e-05   \n",
       "112         en  GERestaurant                    short       acsd  1e-05   \n",
       "44          en  GERestaurant                    short       acsd  1e-05   \n",
       "80          en  GERestaurant                    short       acsd  1e-05   \n",
       "116         en  GERestaurant                    short       acsd  1e-05   \n",
       "148         en  GERestaurant                    short       acsd  1e-05   \n",
       "108         en  GERestaurant                    short       acsd  1e-05   \n",
       "170         en  GERestaurant                    short       acsd  1e-05   \n",
       "146         en  GERestaurant                    short       acsd  1e-05   \n",
       "98          en  GERestaurant                    short       acsd  1e-05   \n",
       "133         en  GERestaurant                    short       acsd  1e-05   \n",
       "100         en  GERestaurant                    short       acsd  1e-05   \n",
       "21          en  GERestaurant                    short       acsd  1e-05   \n",
       "\n",
       "    lora_r lora_alpha lora_dropout model_quant split lr_setting  \\\n",
       "67       8         16         0.05           4     3       full   \n",
       "154      8         16         0.05           4     2       full   \n",
       "69       8         16         0.05           4     1       full   \n",
       "112      8         16         0.05           4     5       full   \n",
       "44       8         16         0.05           4     4       full   \n",
       "80       8         16         0.05           4     2       1000   \n",
       "116      8         16         0.05           4     5       1000   \n",
       "148      8         16         0.05           4     1       1000   \n",
       "108      8         16         0.05           4     4       1000   \n",
       "170      8         16         0.05           4     3       1000   \n",
       "146      8         16         0.05           4     3        500   \n",
       "98       8         16         0.05           4     2        500   \n",
       "133      8         16         0.05           4     4        500   \n",
       "100      8         16         0.05           4     5        500   \n",
       "21       8         16         0.05           4     1        500   \n",
       "\n",
       "                     model_name lang shots prompt  task quant epoch  \\\n",
       "67   meta-llama-Meta-Llama-3-8B   en        short  acsd    16     7   \n",
       "154  meta-llama-Meta-Llama-3-8B   en        short  acsd    16    10   \n",
       "69   meta-llama-Meta-Llama-3-8B   en        short  acsd    16     8   \n",
       "112  meta-llama-Meta-Llama-3-8B   en        short  acsd    16    10   \n",
       "44   meta-llama-Meta-Llama-3-8B   en        short  acsd    16     5   \n",
       "80   meta-llama-Meta-Llama-3-8B   en        short  acsd    16     7   \n",
       "116  meta-llama-Meta-Llama-3-8B   en        short  acsd    16     6   \n",
       "148  meta-llama-Meta-Llama-3-8B   en        short  acsd    16     7   \n",
       "108  meta-llama-Meta-Llama-3-8B   en        short  acsd    16     7   \n",
       "170  meta-llama-Meta-Llama-3-8B   en        short  acsd    16     6   \n",
       "146  meta-llama-Meta-Llama-3-8B   en        short  acsd    16     5   \n",
       "98   meta-llama-Meta-Llama-3-8B   en        short  acsd    16     7   \n",
       "133  meta-llama-Meta-Llama-3-8B   en        short  acsd    16    10   \n",
       "100  meta-llama-Meta-Llama-3-8B   en        short  acsd    16     9   \n",
       "21   meta-llama-Meta-Llama-3-8B   en        short  acsd    16     9   \n",
       "\n",
       "                                          model_config  f1-micro  f1-macro  \\\n",
       "67   en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.7658    0.5835   \n",
       "154  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.7562    0.7241   \n",
       "69   en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.7497    0.6347   \n",
       "112  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.7462    0.6361   \n",
       "44   en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.7327    0.6159   \n",
       "80   en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.6724    0.5932   \n",
       "116  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.6596    0.5679   \n",
       "148  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.6492    0.5152   \n",
       "108  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.6400    0.5185   \n",
       "170  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.6383    0.4975   \n",
       "146  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.5729    0.3874   \n",
       "98   en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.5722    0.4651   \n",
       "133  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.5696    0.4245   \n",
       "100  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.5560    0.5021   \n",
       "21   en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.5413    0.4148   \n",
       "\n",
       "     accuracy  \n",
       "67     0.6205  \n",
       "154    0.6080  \n",
       "69     0.5996  \n",
       "112    0.5952  \n",
       "44     0.5781  \n",
       "80     0.5065  \n",
       "116    0.4921  \n",
       "148    0.4806  \n",
       "108    0.4705  \n",
       "170    0.4688  \n",
       "146    0.4014  \n",
       "98     0.4007  \n",
       "133    0.3983  \n",
       "100    0.3851  \n",
       "21     0.3710  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_max = results_sub.groupby(['model_config', 'split'])['f1-micro'].idxmax()\n",
    "results_per_epoch = results_sub.loc[idx_max]\n",
    "print(len(results_per_epoch))\n",
    "\n",
    "# idx_max = results_per_epoch.groupby(['model_prompt', 'data_setting'])['f1-micro'].idxmax()\n",
    "# results_per_epoch = results_per_epoch.loc[idx_max]\n",
    "# print(len(results_per_epoch))\n",
    "\n",
    "display(results_per_epoch.sort_values(by = ['f1-micro'], ascending = False).head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f78da2-db9e-40cd-ac53-cce4d3ee8481",
   "metadata": {},
   "source": [
    "### Average Performance per Condition with same Epoch for each Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "deef92cb-3ce8-4eab-aead-5c7434d954ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_567312/3425350057.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  results_per_cond = pd.DataFrame(results_sub.groupby(['model_config', 'epoch'], group_keys=False, as_index=False).apply(calcMean).reset_index(), columns = col_names)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_lang</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_shots</th>\n",
       "      <th>model_prompt</th>\n",
       "      <th>model_task</th>\n",
       "      <th>lr</th>\n",
       "      <th>lora_r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>lora_dropout</th>\n",
       "      <th>model_quant</th>\n",
       "      <th>data_setting</th>\n",
       "      <th>model_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>shots</th>\n",
       "      <th>prompt</th>\n",
       "      <th>task</th>\n",
       "      <th>quant</th>\n",
       "      <th>epoch</th>\n",
       "      <th>model_config</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-micro-stdv</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>f1-macro-stdv</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy-stdv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>full</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.0186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ger</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>full</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>ger</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>ger_GERestaurant__short_acsd_1e-05_8_16_0.05_4...</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.0182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ger</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>ger</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>ger_GERestaurant__short_acsd_1e-05_8_16_0.05_4...</td>\n",
       "      <td>0.7471</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.5966</td>\n",
       "      <td>0.0231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.7328</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.6321</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.5788</td>\n",
       "      <td>0.0321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.5190</td>\n",
       "      <td>0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ger</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>ger</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>ger_GERestaurant__short_acsd_1e-05_8_16_0.05_4...</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.5962</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>0.0267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.5843</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.4622</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.4129</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ger</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>ger</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>ger_GERestaurant__short_acsd_1e-05_8_16_0.05_4...</td>\n",
       "      <td>0.5378</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.4489</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.0262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_lang       dataset model_shots model_prompt model_task     lr lora_r  \\\n",
       "31         en  GERestaurant                    short       acsd  1e-05      8   \n",
       "71        ger  GERestaurant                    short       acsd  1e-05      8   \n",
       "59        ger  GERestaurant                    short       acsd  1e-05      8   \n",
       "19         en  GERestaurant                    short       acsd  1e-05      8   \n",
       "1          en  GERestaurant                    short       acsd  1e-05      8   \n",
       "41        ger  GERestaurant                    short       acsd  1e-05      8   \n",
       "21         en  GERestaurant                    short       acsd  1e-05      8   \n",
       "61        ger  GERestaurant                    short       acsd  1e-05      8   \n",
       "\n",
       "   lora_alpha lora_dropout model_quant data_setting  \\\n",
       "31         16         0.05           3         full   \n",
       "71         16         0.05           2         full   \n",
       "59         16         0.05           2         2000   \n",
       "19         16         0.05           3         2000   \n",
       "1          16         0.05           5         1000   \n",
       "41         16         0.05           2         1000   \n",
       "21         16         0.05           3          500   \n",
       "61         16         0.05           2          500   \n",
       "\n",
       "                    model_name lang shots prompt  task quant epoch  \\\n",
       "31  meta-llama-Meta-Llama-3-8B   en        short  acsd    16    10   \n",
       "71  meta-llama-Meta-Llama-3-8B  ger        short  acsd    16    10   \n",
       "59  meta-llama-Meta-Llama-3-8B  ger        short  acsd    16     9   \n",
       "19  meta-llama-Meta-Llama-3-8B   en        short  acsd    16     9   \n",
       "1   meta-llama-Meta-Llama-3-8B   en        short  acsd    16    10   \n",
       "41  meta-llama-Meta-Llama-3-8B  ger        short  acsd    16    10   \n",
       "21  meta-llama-Meta-Llama-3-8B   en        short  acsd    16    10   \n",
       "61  meta-llama-Meta-Llama-3-8B  ger        short  acsd    16    10   \n",
       "\n",
       "                                         model_config  f1-micro  \\\n",
       "31  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.7585   \n",
       "71  ger_GERestaurant__short_acsd_1e-05_8_16_0.05_4...    0.7533   \n",
       "59  ger_GERestaurant__short_acsd_1e-05_8_16_0.05_4...    0.7471   \n",
       "19  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.7328   \n",
       "1   en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.6831   \n",
       "41  ger_GERestaurant__short_acsd_1e-05_8_16_0.05_4...    0.6762   \n",
       "21  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.5843   \n",
       "61  ger_GERestaurant__short_acsd_1e-05_8_16_0.05_4...    0.5378   \n",
       "\n",
       "    f1-micro-stdv  f1-macro  f1-macro-stdv  accuracy  accuracy-stdv  \n",
       "31         0.0143    0.6692         0.0589    0.6112         0.0186  \n",
       "71         0.0141    0.6597         0.0599    0.6045         0.0182  \n",
       "59         0.0182    0.6405         0.0386    0.5966         0.0231  \n",
       "19         0.0262    0.6321         0.0779    0.5788         0.0321  \n",
       "1          0.0158    0.5785         0.0336    0.5190         0.0180  \n",
       "41         0.0232    0.5962         0.0697    0.5112         0.0267  \n",
       "21         0.0144    0.4622         0.0300    0.4129         0.0145  \n",
       "61         0.0283    0.4489         0.0585    0.3682         0.0262  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "col_names = ['model_lang', 'dataset', 'model_shots', 'model_prompt', 'model_task', 'lr', 'lora_r', 'lora_alpha', 'lora_dropout', 'model_quant', 'data_setting', 'model_name', 'lang', 'shots', 'prompt', 'task', 'quant', 'epoch', 'model_config', 'f1-micro', 'f1-micro-stdv', 'f1-macro', 'f1-macro-stdv', 'accuracy', 'accuracy-stdv']\n",
    "\n",
    "def calcMean(group):\n",
    "    f1_micro = []\n",
    "    f1_macro = []\n",
    "    accuracy = []\n",
    "    \n",
    "    for i, row in group.iterrows():\n",
    "        f1_micro.append(row['f1-micro'])\n",
    "        f1_macro.append(row['f1-macro'])\n",
    "        accuracy.append(row['accuracy'])\n",
    "\n",
    "    if(len(f1_micro)) != 5:\n",
    "        print(\"Missing values of %d splits!\" % (5 - len(f1_micro)))\n",
    "        print(\"Model config: \", row['model_config'])\n",
    "        print(\"Epoch: \", row['epoch'])\n",
    "        return pd.Series(0, index = col_names)\n",
    "        \n",
    "    result = list(group.iloc[0, :])[:20]\n",
    "    result.pop(9)\n",
    "    result.append(round(statistics.mean(f1_micro),4))\n",
    "    result.append(round(statistics.stdev(f1_micro),4))\n",
    "    result.append(round(statistics.mean(f1_macro),4))\n",
    "    result.append(round(statistics.stdev(f1_macro),4))\n",
    "    result.append(round(statistics.mean(accuracy),4))\n",
    "    result.append(round(statistics.stdev(accuracy),4))\n",
    "\n",
    "    return pd.Series(result, index = col_names)\n",
    "\n",
    "#results_all = results_all[results_all['model_prompt'] == 'short']\n",
    "\n",
    "# results_per_condition = pd.DataFrame(results_per_split.groupby(\"model_config\", group_keys=False).apply(calcMean), columns = col_names)\n",
    "results_per_cond = pd.DataFrame(results_sub.groupby(['model_config', 'epoch'], group_keys=False, as_index=False).apply(calcMean).reset_index(), columns = col_names)\n",
    "idx_max = results_per_cond.groupby(['model_config'])['f1-micro'].idxmax()\n",
    "results_per_cond = results_per_cond.loc[idx_max]           \n",
    "display(results_per_cond.sort_values(by = ['f1-micro'], ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "011e220a-d43d-47e8-9009-79f579766222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_lang</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_shots</th>\n",
       "      <th>model_prompt</th>\n",
       "      <th>model_task</th>\n",
       "      <th>lr</th>\n",
       "      <th>lora_r</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>lora_dropout</th>\n",
       "      <th>model_quant</th>\n",
       "      <th>data_setting</th>\n",
       "      <th>model_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>shots</th>\n",
       "      <th>prompt</th>\n",
       "      <th>task</th>\n",
       "      <th>quant</th>\n",
       "      <th>epoch</th>\n",
       "      <th>model_config</th>\n",
       "      <th>f1-micro</th>\n",
       "      <th>f1-micro-stdv</th>\n",
       "      <th>f1-macro</th>\n",
       "      <th>f1-macro-stdv</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy-stdv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>full</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.7478</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.5973</td>\n",
       "      <td>0.0161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.5383</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.4816</td>\n",
       "      <td>0.0161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>en</td>\n",
       "      <td>GERestaurant</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>meta-llama-Meta-Llama-3-8B</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>short</td>\n",
       "      <td>acsd</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...</td>\n",
       "      <td>0.5595</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.4353</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.3885</td>\n",
       "      <td>0.0130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_lang       dataset model_shots model_prompt model_task     lr lora_r  \\\n",
       "28         en  GERestaurant                    short       acsd  1e-05      8   \n",
       "7          en  GERestaurant                    short       acsd  1e-05      8   \n",
       "17         en  GERestaurant                    short       acsd  1e-05      8   \n",
       "\n",
       "   lora_alpha lora_dropout model_quant data_setting  \\\n",
       "28         16         0.05           3         full   \n",
       "7          16         0.05           2         1000   \n",
       "17         16         0.05           2          500   \n",
       "\n",
       "                    model_name lang shots prompt  task quant epoch  \\\n",
       "28  meta-llama-Meta-Llama-3-8B   en        short  acsd    16     8   \n",
       "7   meta-llama-Meta-Llama-3-8B   en        short  acsd    16     7   \n",
       "17  meta-llama-Meta-Llama-3-8B   en        short  acsd    16     7   \n",
       "\n",
       "                                         model_config  f1-micro  \\\n",
       "28  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.7478   \n",
       "7   en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.6500   \n",
       "17  en_GERestaurant__short_acsd_1e-05_8_16_0.05_4_...    0.5595   \n",
       "\n",
       "    f1-micro-stdv  f1-macro  f1-macro-stdv  accuracy  accuracy-stdv  \n",
       "28         0.0126    0.6586         0.0423    0.5973         0.0161  \n",
       "7          0.0146    0.5383         0.0390    0.4816         0.0161  \n",
       "17         0.0136    0.4353         0.0471    0.3885         0.0130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_per_cond.sort_values(by = ['f1-micro'], ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f863cf0-481f-41a5-aa50-d99797227362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_configs = results_all.groupby(['model_config', 'split'])\n",
    "\n",
    "gr = [model_configs.get_group(x) for x in model_configs.groups]\n",
    "\n",
    "for x in gr:\n",
    "    f1 = pd.DataFrame(x)\n",
    "    f1['epoch'] = f1['epoch'].astype(int)\n",
    "    f1 = f1.sort_values(by = ['epoch'])\n",
    "    f1 = f1.set_index('epoch')\n",
    "    title = f1.reset_index()['model_config'][0]\n",
    "    f1[['f1-micro', 'f1-macro', 'accuracy']].plot(title=title, ylim=(0.6, 0.8))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2c1e8-9577-4985-bd30-d5b17201abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names = [folder for folder in os.listdir(path) if os.path.isdir(os.path.join(path, folder)) and folder != '.ipynb_checkpoints']\n",
    "\n",
    "path = './results/'\n",
    "\n",
    "runs = []\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    try:\n",
    "        df = pd.read_csv(path + folder_name + '/metrics_asp_pol.tsv', sep = '\\t')\n",
    "        df = df.set_index(df.columns[0])\n",
    "        cond_name = folder_name.split('/')[-1]\n",
    "        cond_parameters = cond_name.split('_')\n",
    "        cond_parameters.append('_'.join(cond_parameters[:-1]))\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Macro-AVG', 'f1'])\n",
    "        cond_parameters.append(df.loc['Micro-AVG', 'accuracy'])\n",
    "        runs.append(cond_parameters)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "results = pd.DataFrame(runs, columns = col_names)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_configs = results.groupby('model_config')\n",
    "\n",
    "gr = [model_configs.get_group(x) for x in model_configs.groups]\n",
    "\n",
    "for x in gr:\n",
    "    f1 = pd.DataFrame(x)\n",
    "    f1['epoch'] = f1['epoch'].astype(int)\n",
    "    f1 = f1.sort_values(by = ['epoch'])\n",
    "    f1 = f1.set_index('epoch')\n",
    "    title = f1.reset_index()['model_config'][0]\n",
    "    f1[['f1-micro', 'f1-macro', 'accuracy']].plot(title=title, ylim=(0.6, 0.8))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b48893-4c50-4762-b153-89870d251d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ...\n",
      "Dataset name: GERestaurant\n",
      "Split setting:  Custom\n",
      "Eval Mode:  Validation\n",
      "Low Resource Setting:  0\n",
      "Train Length:  1795\n",
      "Eval Length:  359\n",
      "Split: 0\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import utils.preprocessing\n",
    "import utils.evaluation\n",
    "\n",
    "reload(utils.preprocessing)\n",
    "\n",
    "args = lambda: None\n",
    "args.lang = \"en\"\n",
    "args.prompt_style = \"short\"\n",
    "args.dataset = 'GERestaurant'\n",
    "args.split = 0\n",
    "args.lr_setting = 500\n",
    "args.task = 'tasd'\n",
    "\n",
    "df_train, df_test, label_space = utils.preprocessing.loadDataset(args.dataset, args.split, args.lr_setting)\n",
    "prompts_train, prompts_test, ground_truth_labels = utils.preprocessing.createPrompts(df_train, df_test, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64992da6-793a-4954-837d-6a03050e507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AMBIENCE', 'POSITIVE', 'Atmung'],\n",
       " ['AMBIENCE', 'POSITIVE', 'Deko an Wänden']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.evaluation.extractAspects('[' + ', '.join(df_train['labels_phrases'][0]) + ']', 'tasd', False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "50a5fbc8-46c5-4cd4-a320-a677e4db0b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrahiere alle Aspekte, die im Satz angesprochen werden und gib diese als Liste zurück. Gib eine leere Liste zurück, sofern im Satz keine Aspekte angesprochen werden. Gib nur die Liste zurück, ohne weitere Kommentare oder Text.\n",
      "\n",
      "* Berücksichtige folgende Aspekte: [\"ESSEN&TRINKEN\", \"SERVICE\", \"PREIS\", \"AMBIENTE\", \"ALLGEMEINER-EINDRUCK\"].\n",
      "* Berücksichtige folgende Sentiment-Polaritäten: [\"negativ\", \"neutral\", \"positiv\"].\n",
      "\n",
      "\"ESSEN&TRINKEN\" bezieht sich auf das Essen im Allgemeinen oder bestimmte Speisen und Getränke. \"SERVICE\" umfasst Bewertungen zum Service im Allgemeinen, zur Einstellung des Personals, Wartezeiten oder Service-Dienstleistungen wie Speisenmitnahme. \"PREIS\" betrifft Bewertungen zum allgemeinen Preisniveau oder zu Preisen von Speisen, Getränken oder anderen Leistungen des Restaurants. \"AMBIENTE\" bezieht sich auf die Atmosphäre im Innen- und Außenbereich des Restaurants, die Ausstattung und Unterhaltungsmöglichkeiten. \"ALLGEMEINER-EINDRUCK\" umfasst Bewertungen zum Restaurant als Ganzes, ohne Fokus auf die genannten Aspekt-Kategorien.\n",
      "\n",
      "Die Labels \"positiv\", \"neutral\" und \"negativ\" stehen für das positive, neutrale oder negative Sentiment gegenüber dem jeweiligen Aspekt.\n",
      "\n",
      "### Input:\n",
      "Sehr schöne Lage mit Blick auf die LOC. \n",
      "\n",
      "### Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[0]['messages'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "20c2934b-2c4d-435d-ad95-b685f646df28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(SERVICE, negative)]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[0]['messages'][2]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c517891a-3e25-4ba3-a0da-da9c61610391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import utils.absaHelpers2\n",
    "from utils.absaHelpers2 import loadDataset, createPrompts\n",
    "\n",
    "reload(utils.absaHelpers2)\n",
    "\n",
    "from utils.absaHelpers2 import loadDataset, createPrompts\n",
    "\n",
    "\n",
    "args = lambda: None\n",
    "args.shots = \"10shot_rand\"\n",
    "args.lang = \"ger\"\n",
    "args.prompt_style = \"short\"\n",
    "args.dataset = 'rest'\n",
    "args.split = 1\n",
    "args.low_resource_setting = 500\n",
    "args.task = 'acsd'\n",
    "\n",
    "df_train, df_test, label_space = loadDataset(args.dataset, args.split, args.low_resource_setting)\n",
    "dataset_train, dataset_test, ground_truth_labels = createPrompts(df_train, df_test, args, output_format = 'str', model_type = \"llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "0c62c45b-4a7b-43b0-b78e-0c1f1ccc9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Du bist eine hochentwickelte KI für die Textklassifikation, spezialisiert auf Aspekt-basierte Sentiment-Analyse in deutschsprachigen Texten. Extrahiere alle (Aspekt, Sentiment, Aspektphrase)-Tripel eines Satzes, indem du alle angesprochenen Aspektkategorien [\"ESSEN&TRINKEN\", \"SERVICE\", \"PREIS\", \"AMBIENTE\", \"ALLGEMEINER-EINDRUCK\"] und die dazugehörigen Phrasen identifizierst und die ausgedrückte Sentiment-Polarität [\"negativ\", \"neutral\", \"positiv\"] gegenüber jedem Aspekt analysierst. Gib eine Liste von Tripeln zurück, die für jedes Aspekt jeweils drei Zeichenketten in Klammern enthalten. Wenn ein Aspekt impliziert, aber nicht explizit genannt wird, weise der Aspektphrase \"NULL\" zu.\n",
      "\n",
      "### Input:\n",
      "Das Bier ist klasse, genau wie die Lokation. \n",
      "\n",
      "### Output:\n",
      "[(ESSEN&TRINKEN, positiv, \"Bier\"), (AMBIENTE, positiv, \"Lokation\")]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "82d99961-58f1-499e-8b9f-ee06a13957a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Du bist eine hochentwickelte KI für die Textklassifikation, spezialisiert auf Aspekt-basierte Sentiment-Analyse in deutschsprachigen Texten. Extrahiere alle (Aspekt, Sentiment, Aspektphrase)-Tripel eines Satzes, indem du alle angesprochenen Aspektkategorien [\"ESSEN&TRINKEN\", \"SERVICE\", \"PREIS\", \"AMBIENTE\", \"ALLGEMEINER-EINDRUCK\"] und die dazugehörigen Phrasen identifizierst und die ausgedrückte Sentiment-Polarität [\"negativ\", \"neutral\", \"positiv\"] gegenüber jedem Aspekt analysierst. Gib eine Liste von Tripeln zurück, die für jedes Aspekt jeweils drei Zeichenketten in Klammern enthalten. Wenn ein Aspekt impliziert, aber nicht explizit genannt wird, weise der Aspektphrase \"NULL\" zu.\n",
      "\n",
      "Ein paar Beispiele:\n",
      "Satz: Kaninchen, Tintenfisch und Spinatrollen konnten uns überhaupt nicht überzeugen. \n",
      "Aspekt-Sentiment-Paare: [(ESSEN&TRINKEN, negativ, \"Kaninchen\"), (ESSEN&TRINKEN, negativ, \"Tintenfisch\"), (ESSEN&TRINKEN, negativ, \"Spinatrollen\")]\n",
      "\n",
      "Satz: Kindermenü super Preis-Leistung, Getränke ziemlich teuer. \n",
      "Aspekt-Sentiment-Paare: [(PREIS, positiv, \"Preis-Leistung\"), (PREIS, negativ, \"Getränke\")]\n",
      "\n",
      "Satz: Das Essen ist mittelmäßig, geschmacklich kein Highlight, kein Unterschied zu einem normalen Asia Imbiss. \n",
      "Aspekt-Sentiment-Paare: [(ESSEN&TRINKEN, neutral, \"Essen\")]\n",
      "\n",
      "Satz: Die LOC war recht geschmacklos. \n",
      "Aspekt-Sentiment-Paare: [(ESSEN&TRINKEN, negativ, \"LOC\")]\n",
      "\n",
      "Satz: Sehr unhöflicher Kellner. \n",
      "Aspekt-Sentiment-Paare: [(SERVICE, negativ, \"Kellner\")]\n",
      "\n",
      "Satz: Was aber gar nicht geht, wenn zur happy hour- Zeit nur 0,4 statt 0,5 l eingeschenkt wird (schlechter eingeschenkt) um den billigeren Preis wett zu machen. \n",
      "Aspekt-Sentiment-Paare: [(SERVICE, negativ, \"NULL\")]\n",
      "\n",
      "Satz: Schade, schade. \n",
      "Aspekt-Sentiment-Paare: [(ALLGEMEINER-EINDRUCK, negativ, \"NULL\")]\n",
      "\n",
      "Satz: Wir wollten ein tolles Abendessen in dem Restaurant genießen, leider war schon die Stimmung nicht wirklich toll, der Chef hat die Bedienungen von den Gästen kritisiert, das ist nicht angebracht. \n",
      "Aspekt-Sentiment-Paare: [(AMBIENTE, negativ, \"Stimmung\"), (SERVICE, negativ, \"Chef\")]\n",
      "\n",
      "Satz: Als Hauptgericht war haben ein Steinbutt bestellt aber der Fish der serviert wurde hatte vielleicht mal ein Steinbutt von weitem gesehen. \n",
      "Aspekt-Sentiment-Paare: [(ESSEN&TRINKEN, negativ, \"Fish\")]\n",
      "\n",
      "Satz: Wir haben es zwar gegessen, aber bereits zu Beginn erneut reklamiert. \n",
      "Aspekt-Sentiment-Paare: [(ESSEN&TRINKEN, negativ, \"NULL\")]\n",
      "\n",
      "### Input:\n",
      "Immer wieder gerne. \n",
      "\n",
      "### Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f0e684a0-0e07-4073-9419-61ba07d96be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import utils.absaHelpers2\n",
    "from utils.absaHelpers2 import loadDataset, createPrompts\n",
    "\n",
    "reload(utils.absaHelpers2)\n",
    "\n",
    "from utils.absaHelpers2 import loadDataset, createPrompts\n",
    "\n",
    "\n",
    "args = lambda: None\n",
    "args.shots = \"\"\n",
    "args.lang = \"ger\"\n",
    "args.prompt_style = \"short\"\n",
    "args.dataset = 'rest'\n",
    "args.split = 1\n",
    "args.low_resource_setting = 500\n",
    "args.task = 'acd'\n",
    "\n",
    "df_train, df_test, label_space = loadDataset(args.dataset, args.split, args.low_resource_setting)\n",
    "dataset_train, dataset_test, ground_truth_labels = createPrompts(df_train, df_test, args, model_type = \"llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "150b334b-3af3-4b84-b16f-b07b7b29a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Du bist eine hochentwickelte KI für die Textklassifikation, spezialisiert auf Aspekt-basierte Sentiment-Analyse in deutschsprachigen Texten. Extrahiere alle Aspekte [\"ESSEN&TRINKEN\", \"SERVICE\", \"PREIS\", \"AMBIENTE\", \"ALLGEMEINER-EINDRUCK\"], die im Satz angesprochen werden und gib diese als Liste zurück.\n",
      "\n",
      "### Input:\n",
      "Die Bedienung war früher sehr viel herzlicher und mit Herzblut dabei. \n",
      "\n",
      "### Output:\n",
      "[(SERVICE, negative)]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5401527d-982b-4f46-bdc2-b27266e94076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Du bist eine hochentwickelte KI für die Textklassifikation, spezialisiert auf Aspekt-basierte Sentiment-Analyse in deutschsprachigen Texten. Extrahiere alle Aspekte [\"ESSEN&TRINKEN\", \"SERVICE\", \"PREIS\", \"AMBIENTE\", \"ALLGEMEINER-EINDRUCK\"], die im Satz angesprochen werden und gib diese als Liste zurück.\n",
      "\n",
      "### Input:\n",
      "Dass man aber 5 Minuten warten muss, bis jemandem ein Kellner erklärt, dass man einen Engpass hat, ist dann schon ein starkes Stück. \n",
      "\n",
      "### Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde24003-556a-4313-882c-6e5c0cac00de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ...\n",
      "Dataset name: rest-16\n",
      "Split setting:  Custom\n",
      "Eval Mode:  Test\n",
      "Low Resource Setting:  500\n",
      "Train Length:  333\n",
      "Eval Length:  284\n",
      "Split: 1\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import utils.preprocessing\n",
    "from utils.preprocessing import loadDataset, createPrompts\n",
    "\n",
    "reload(utils.preprocessing)\n",
    "\n",
    "from utils.preprocessing import loadDataset, createPrompts\n",
    "\n",
    "\n",
    "args = lambda: None\n",
    "args.shots = \"5shot_rand\"\n",
    "args.lang = \"en\"\n",
    "args.prompt_style = \"cot\"\n",
    "args.dataset = 'rest-16'\n",
    "args.split = 1\n",
    "args.low_resource_setting = 500\n",
    "args.task = 'acsd'\n",
    "\n",
    "df_train, df_test, label_space = loadDataset(args.dataset, args.low_resource_setting, args.task, args.split,  False)\n",
    "prompts_train, prompts_test, ground_truth_labels = createPrompts(df_train, df_test, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1beb0a8-4fd4-4902-9873-8f10ae427bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "You are an advanced AI for text classification, specialized in aspect-based sentiment analysis for texts in English. Extract all (aspect, sentiment, aspect phrase) triples of a sentence by identifying all the aspect categories addressed with their corresponding phrases and analyzing the sentiment expressed towards each aspect. Return a list of triples, each containing three strings in parentheses. If an aspect is implied but not explicitly stated, identify its aspect category and its sentiment and assign the aspect phrase \"NULL\". Return an empty list if no aspects are addressed in the sentence. Return only the list, without any further comments or text.\n",
      "\n",
      "* Consider the following aspects: [AMBIENCE#GENERAL, DRINKS#PRICES, DRINKS#QUALITY, DRINKS#STYLE_OPTIONS, FOOD#PRICES, FOOD#QUALITY, FOOD#STYLE_OPTIONS, LOCATION#GENERAL, SERVICE#GENERAL, RESTAURANT#GENERAL, RESTAURANT#PRICES, RESTAURANT#MISCELLANEOUS].\n",
      "* Consider the following sentiment polarities: [POSITIVE, NEUTRAL, NEGATIVE].\n",
      "\n",
      "AMBIENCE#GENERAL refers to the atmosphere inside and outside the restaurant, the facilities and the general noise level in the restaurant. DRINKS#PRICES refers to the general pricing level of the drinks, DRINKS#QUALITY refers to the quality of the drinks and DRINKS#STYLE_OPTIONS refers to the selection of drinks and the variety of the drinks menu. FOOD#PRICES refers to the general pricing level of the food, FOOD#QUALITY refers to the quality of the food and FOOD#STYLE_OPTIONS refers to the selection of food and the variety of the food menu. LOCATION#GENERAL refers the the location of the restaurant. SERVICE#GENERAL includes ratings on the service in general, the attitude of the staff, waiting times or other services such as takeaway. RESTAURANT#GENERAL refers to general opinions about the restaurant, RESTAURANT#PRICES refers to the general pricing level of a restaurant visit and RESTAURANT#MISCELLANEOUS includes miscellaneous opinions about the restaurant, without focus on the aspect categories already mentioned. \n",
      "The labels POSITIVE, NEUTRAL and NEGATIVE describe the positive, neutral or negative sentiment expressed towards the aspect.\n",
      "\n",
      "### Input:\n",
      "We both opted for a pasta dish and they were served timely and fresh. \n",
      "\n",
      "### Output:\n",
      "Lets do this step by step. We would like to extract all aspect-sentiment-phrase-triples from the following sentence: \"We both opted for a pasta dish and they were served timely and fresh.\". First, we identify all aspects addressed in the sentence and their corresponding phrases: The aspect FOOD#QUALITY is referenced with the phrase \"pasta dish\" while the aspect SERVICE#GENERAL  is inferred from the context of the sentence and is therefore referenced without a phrase. We thus assign its phrase the value \"NULL\". Next, we determine the sentiment expressed towards these aspects: The aspect FOOD#QUALITY is referenced positively and the aspect SERVICE#GENERAL is mentioned positively in the text. \n",
      "The final result thus consists of the following aspect-sentiment-phrase-triples: [(FOOD#QUALITY, POSITIVE, \"pasta dish\"), (SERVICE#GENERAL, POSITIVE, \"NULL\")]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompts_train[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4877401d-454f-4026-80ba-1ca628926ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "You are an advanced AI for text classification, specialized in aspect-based sentiment analysis for texts in German. Extract all (aspect, sentiment, aspect phrase) triples of a sentence by identifying all the aspect categories addressed and the corresponding phrases and analyzing the sentiment expressed towards each aspect. Return a list of triples, each containing three strings in parentheses. If an aspect is implied but not explicitly stated, identify its aspect category and assign the aspect phrase \"NULL\". Return an empty list if no aspects are addressed in the sentence. Return only the list, without any further comments or text.\n",
      "\n",
      "* Consider the following aspects: [FOOD, SERVICE, PRICE, AMBIENCE, GENERAL-IMPRESSION].\n",
      "* Consider the following sentiment polarities: [POSITIVE, NEUTRAL, NEGATIVE].\n",
      "\n",
      "FOOD refers to the food in general or specific dishes and drinks. SERVICE includes ratings on the service in general, the attitude of the staff, waiting times or other services such as takeaway. PRICE relates to opinions on the general pricing level or prices of food, drinks or other restaurant services. AMBIENCE refers to the atmosphere inside and outside the restaurant, the facilities and the general noise level in the restaurant. GENERAL-IMPRESSION includes opinions on the restaurant as a whole, without focus on the aspect categories mentioned. \n",
      "The labels POSITIVE, NEUTRAL and NEGATIVE describe the positive, neutral or negative sentiment expressed towards the aspect.\n",
      "\n",
      "A few examples:\n",
      "Lets do this step by step. We would like to extract all aspect-sentiment-phrase-triples from the following sentence: \"Die Pasta-Gerichte waren gut aber mit Preisen teilweise weit über 20€ zu teuer, es waren dann zwar gut gemachte, gut schmeckende Speisen, aber nicht das Geld wert.\". First, we identify all aspects addressed in the sentence and their corresponding phrases: The aspect PREIS is referenced with the phrase \"Preisen\", the aspect ESSEN&TRINKEN is referenced with the phrase \"Pasta-Gerichte\", the aspect ESSEN&TRINKEN is referenced with the phrase \"Speisen\", the aspect PREIS is referenced with the phrase \"Speisen\" and the aspect PREIS is referenced with the phrase \"Pasta-Gerichte\". Next, we determine the sentiment expressed towards these aspects: The aspect PREIS is mentioned negatively, the aspect ESSEN&TRINKEN is mentioned positively, the aspect ESSEN&TRINKEN is mentioned positively, the aspect PREIS is mentioned negatively and the aspect PREIS is mentioned negatively in the text. \n",
      "The final result thus consists of the following aspect-sentiment-phrase-triples: [(PREIS, negativ, \"Preisen\"), (ESSEN&TRINKEN, positiv, \"Pasta-Gerichte\"), (ESSEN&TRINKEN, positiv, \"Speisen\"), (PREIS, negativ, \"Speisen\"), (PREIS, negativ, \"Pasta-Gerichte\")]\n",
      "\n",
      "Lets do this step by step. We would like to extract all aspect-sentiment-phrase-triples from the following sentence: \"LOC mit abwechslungsreichen Speiseangebot, der Service ist eingedeutscht.\". First, we identify all aspects addressed in the sentence and their corresponding phrases: The aspect SERVICE is referenced with the phrase \"Service\" and the aspect ESSEN&TRINKEN is referenced with the phrase \"Speiseangebot\" in the text. Next, we determine the sentiment expressed towards these aspects: The aspect SERVICE is referenced negatively and the aspect ESSEN&TRINKEN is mentioned positively in the text. \n",
      "The final result thus consists of the following aspect-sentiment-phrase-triples: [(SERVICE, negativ, \"Service\"), (ESSEN&TRINKEN, positiv, \"Speiseangebot\")]\n",
      "\n",
      "Lets do this step by step. We would like to extract all aspect-sentiment-phrase-triples from the following sentence: \"Hoffnungslos überteuert bei miserabler Qualität und einem Koch, der kein Deutsch versteht.\". First, we identify the aspect addressed in the sentence and its corresponding phrase: The aspect SERVICE is referenced with the phrase \"Koch\". The aspects PREIS and ALLGEMEINER-EINDRUCK are inferred from the context of the sentence and are therefore referenced without a phrase. We thus assign their phrases the value \"NULL\". Next, we determine the sentiment expressed towards these aspects: The aspect SERVICE is mentioned negatively, the aspect PREIS is mentioned negatively and the aspect ALLGEMEINER-EINDRUCK is mentioned negatively in the text. \n",
      "The final result thus consists of the following aspect-sentiment-phrase-triples: [(PREIS, negativ, \"NULL\"), (SERVICE, negativ, \"Koch\"), (ALLGEMEINER-EINDRUCK, negativ, \"NULL\")]\n",
      "\n",
      "Lets do this step by step. We would like to extract all aspect-sentiment-phrase-triples from the following sentence: \"Keinen Platz im Obergeschoss trotz mehrerer freier Tische zu bekommen, weil wir das winzige Schild übersehen haben, dass man platziert wird, hat uns nicht gefreut.\". First, we identify the aspect addressed in the sentence and its corresponding phrase: The aspect SERVICE is inferred from the context of the sentence and is therefore referenced without a phrase. We thus assign its phrase the value \"NULL\". Next, we determine the sentiment expressed towards this aspect: The aspect SERVICE is mentioned negatively in the text. \n",
      "The final result thus consists of the following aspect-sentiment-phrase-triple: [(SERVICE, negativ, \"NULL\")]\n",
      "\n",
      "Lets do this step by step. We would like to extract all aspect-sentiment-phrase-triples from the following sentence: \"Auch die Knödel sind sehr lecker 😋 Habe ein Dessert gegessen, auch dass war schön angerichtet und 😋.\". First, we identify all aspects addressed in the sentence and their corresponding phrases: The aspect ESSEN&TRINKEN is referenced with the phrase \"Knödel\" and the aspect ESSEN&TRINKEN is referenced with the phrase \"Dessert\" in the text. Next, we determine the sentiment expressed towards these aspects: The aspect ESSEN&TRINKEN is referenced positively and the aspect ESSEN&TRINKEN is mentioned positively in the text. \n",
      "The final result thus consists of the following aspect-sentiment-phrase-triples: [(ESSEN&TRINKEN, positiv, \"Knödel\"), (ESSEN&TRINKEN, positiv, \"Dessert\")]\n",
      "\n",
      "### Input:\n",
      "Wir wurden rundherum bestens bedient. \n",
      "\n",
      "### Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa4bfcc9-215a-4526-952c-7bf43dc6fac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=12.0, pvalue=0.90625)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "long_500 = (0.7530, 0.7761, 0.7669, 0.7752, 0.7573)\n",
    "long_1000 = (0.7800, 0.7729, 0.7967, 0.7696, 0.7766)\n",
    "\n",
    "stats.wilcoxon(long_1000, long_500, alternative = 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0c0688c-d2ef-45dd-9576-e7d40c412a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=12.0, pvalue=0.15625)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.wilcoxon(long_1000, long_500, alternative = 'greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "86291a2e-acae-47a5-a6fe-6cae2e93e8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=3.0, pvalue=0.3125)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.wilcoxon(long_1000, long_500, alternative = 'two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f142b1f-6d0f-4fc4-b798-f1ead9a3e714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393.4056989990335"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import statsmodels.stats.power as smp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "power_analysis = smp.TTestIndPower()\n",
    "sample_size = power_analysis.solve_power(effect_size=0.2, power=0.8, alpha=0.05)\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "41b56253-a77b-43b0-841f-7b5980f9e2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7657\n",
      "0.7791600000000001\n"
     ]
    }
   ],
   "source": [
    "print(sum(long_500)/len(long_500))\n",
    "print(sum(long_1000)/len(long_1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a7eeadf-8104-4e0b-8d82-3e3208e651fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.absaHelpers' from '/home/jupyter/shared/notebooks/Finetune LLMs/utils/absaHelpers.py'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(utils.absaHelpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1e262283-454e-4cf0-9cf6-268f318d8ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ...\n",
      "Dataset name: GERestaurant\n",
      "Split setting:  Custom\n",
      "Eval Mode:  Validation\n",
      "Low Resource Setting:  0\n",
      "Train Length:  1795\n",
      "Eval Length:  359\n",
      "Split: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_phrases</th>\n",
       "      <th>25shot_rand</th>\n",
       "      <th>10shot_rand</th>\n",
       "      <th>5shot_rand</th>\n",
       "      <th>25shot_asp</th>\n",
       "      <th>10shot_asp</th>\n",
       "      <th>5shot_asp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Preislich vollkommen okay Immer wieder gern.</td>\n",
       "      <td>[(GENERAL-IMPRESSION, POSITIVE), (PRICE, NEUTR...</td>\n",
       "      <td>[(GENERAL-IMPRESSION, POSITIVE, \"NULL\"), (PRIC...</td>\n",
       "      <td>[15, 1298, 2058, 746, 822, 402, 771, 1023, 203...</td>\n",
       "      <td>[74, 602, 1328, 531, 3, 1988, 1929, 419, 1505,...</td>\n",
       "      <td>[1483, 389, 1132, 1702, 1277]</td>\n",
       "      <td>[1365, 1371, 523, 954, 391, 1532, 98, 1176, 94...</td>\n",
       "      <td>[1056, 1949, 1652, 1524, 1131, 1901, 1780, 863...</td>\n",
       "      <td>[1628, 1797, 533, 1115, 1339]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mein Besuch mit einer Gruppe von 16 Personen w...</td>\n",
       "      <td>[(GENERAL-IMPRESSION, POSITIVE)]</td>\n",
       "      <td>[(GENERAL-IMPRESSION, POSITIVE, \"NULL\")]</td>\n",
       "      <td>[28, 2141, 419, 1949, 457, 831, 109, 741, 3, 3...</td>\n",
       "      <td>[874, 640, 1962, 178, 2039, 873, 889, 739, 871...</td>\n",
       "      <td>[2075, 1122, 1192, 945, 695]</td>\n",
       "      <td>[1143, 656, 952, 712, 1467, 773, 545, 1294, 98...</td>\n",
       "      <td>[1382, 447, 1904, 635, 1118, 380, 767, 56, 166...</td>\n",
       "      <td>[1780, 119, 2122, 883, 1373]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Der Wein eher gewöhnungsbedürftig!</td>\n",
       "      <td>[(FOOD, NEGATIVE)]</td>\n",
       "      <td>[(FOOD, NEGATIVE, \"Wein\")]</td>\n",
       "      <td>[333, 37, 1720, 1643, 1454, 708, 663, 1381, 27...</td>\n",
       "      <td>[54, 1414, 1138, 1374, 1852, 1262, 670, 1161, ...</td>\n",
       "      <td>[1766, 728, 568, 49, 1731]</td>\n",
       "      <td>[1824, 2081, 1983, 847, 1047, 39, 1052, 995, 1...</td>\n",
       "      <td>[1324, 1391, 1170, 373, 1615, 1407, 1470, 1897...</td>\n",
       "      <td>[1710, 1087, 686, 712, 1844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vorspeise war zwar sehr lecker und kam nach ca.</td>\n",
       "      <td>[(FOOD, POSITIVE)]</td>\n",
       "      <td>[(FOOD, POSITIVE, \"Vorspeise\")]</td>\n",
       "      <td>[1584, 1737, 510, 756, 1172, 732, 1472, 1567, ...</td>\n",
       "      <td>[2133, 978, 363, 1427, 1001, 1901, 1015, 199, ...</td>\n",
       "      <td>[587, 1745, 1089, 901, 506]</td>\n",
       "      <td>[1583, 27, 1357, 1449, 1456, 1824, 898, 646, 1...</td>\n",
       "      <td>[729, 1972, 718, 381, 1274, 2108, 1353, 1853, ...</td>\n",
       "      <td>[973, 484, 1177, 1082, 250]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Beilagensalat klein, kaum Dressung und lieblos.</td>\n",
       "      <td>[(FOOD, NEGATIVE), (FOOD, NEGATIVE)]</td>\n",
       "      <td>[(FOOD, NEGATIVE, \"Beilagensalat\"), (FOOD, NEG...</td>\n",
       "      <td>[1398, 1584, 334, 2068, 1988, 685, 793, 1544, ...</td>\n",
       "      <td>[158, 759, 728, 382, 578, 389, 1880, 592, 379,...</td>\n",
       "      <td>[1887, 641, 1824, 1586, 517]</td>\n",
       "      <td>[1637, 1975, 119, 765, 578, 1029, 1807, 231, 1...</td>\n",
       "      <td>[1672, 1648, 1802, 1618, 1241, 809, 211, 1737,...</td>\n",
       "      <td>[1341, 578, 27, 1092, 1107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Das \"neue\" Thai &amp; Turf hat leider nichts mehr ...</td>\n",
       "      <td>[(GENERAL-IMPRESSION, NEGATIVE)]</td>\n",
       "      <td>[(GENERAL-IMPRESSION, NEGATIVE, \"Thai &amp; Turf\")]</td>\n",
       "      <td>[178, 1493, 377, 1890, 1063, 381, 88, 1240, 21...</td>\n",
       "      <td>[1875, 832, 745, 1128, 1160, 681, 994, 1781, 6...</td>\n",
       "      <td>[1807, 820, 226, 842, 1047]</td>\n",
       "      <td>[263, 1475, 2023, 37, 2122, 729, 676, 2079, 14...</td>\n",
       "      <td>[1783, 1704, 1909, 1368, 2066, 1868, 1691, 969...</td>\n",
       "      <td>[819, 815, 934, 455, 1130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Der Besuch bleibt in Erinnerung.</td>\n",
       "      <td>[(GENERAL-IMPRESSION, POSITIVE)]</td>\n",
       "      <td>[(GENERAL-IMPRESSION, POSITIVE, \"NULL\")]</td>\n",
       "      <td>[1428, 1625, 816, 1367, 1334, 465, 362, 1813, ...</td>\n",
       "      <td>[1281, 1155, 2047, 1636, 1372, 2115, 1832, 194...</td>\n",
       "      <td>[842, 733, 1658, 725, 916]</td>\n",
       "      <td>[73, 195, 1635, 1768, 983, 1176, 211, 1877, 15...</td>\n",
       "      <td>[725, 928, 1548, 1225, 147, 208, 1476, 1116, 7...</td>\n",
       "      <td>[533, 903, 769, 111, 1709]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wir waren jetzt schon zum 4 Mal hier im August...</td>\n",
       "      <td>[(GENERAL-IMPRESSION, POSITIVE)]</td>\n",
       "      <td>[(GENERAL-IMPRESSION, POSITIVE, \"Augustiner\")]</td>\n",
       "      <td>[1854, 1338, 683, 454, 944, 102, 625, 2130, 25...</td>\n",
       "      <td>[839, 1676, 1734, 1942, 125, 114, 1077, 1916, ...</td>\n",
       "      <td>[676, 1804, 154, 453, 158]</td>\n",
       "      <td>[1273, 1362, 722, 1242, 1503, 1227, 1847, 1570...</td>\n",
       "      <td>[830, 1750, 637, 1176, 2020, 1522, 85, 44, 124...</td>\n",
       "      <td>[990, 1458, 1029, 1394, 277]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Eine normale Unterhaltung ist aufgrund der Lau...</td>\n",
       "      <td>[(AMBIENCE, NEGATIVE)]</td>\n",
       "      <td>[(AMBIENCE, NEGATIVE, \"Lautstärke\")]</td>\n",
       "      <td>[65, 2073, 2076, 602, 683, 1922, 9, 997, 669, ...</td>\n",
       "      <td>[1905, 229, 419, 1231, 765, 1042, 49, 1839, 13...</td>\n",
       "      <td>[1337, 1597, 950, 447, 830]</td>\n",
       "      <td>[1893, 736, 1566, 968, 64, 1768, 552, 581, 108...</td>\n",
       "      <td>[1531, 1655, 2106, 1609, 629, 44, 833, 1136, 7...</td>\n",
       "      <td>[186, 602, 2063, 277, 1826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Die Bedienung hatte wenig Lächeln übrig, war d...</td>\n",
       "      <td>[(SERVICE, NEGATIVE)]</td>\n",
       "      <td>[(SERVICE, NEGATIVE, \"Bedienung\")]</td>\n",
       "      <td>[1298, 740, 1976, 387, 276, 1446, 1237, 1664, ...</td>\n",
       "      <td>[1347, 1467, 35, 1117, 338, 1987, 1536, 757, 8...</td>\n",
       "      <td>[1560, 588, 2043, 691, 1277]</td>\n",
       "      <td>[1059, 502, 1053, 866, 1875, 1104, 1047, 570, ...</td>\n",
       "      <td>[1487, 1691, 495, 1707, 541, 4, 1368, 670, 141...</td>\n",
       "      <td>[1451, 574, 1423, 1068, 675]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "id                                                      \n",
       "5        Preislich vollkommen okay Immer wieder gern.   \n",
       "7   Mein Besuch mit einer Gruppe von 16 Personen w...   \n",
       "11                 Der Wein eher gewöhnungsbedürftig!   \n",
       "17    Vorspeise war zwar sehr lecker und kam nach ca.   \n",
       "26    Beilagensalat klein, kaum Dressung und lieblos.   \n",
       "36  Das \"neue\" Thai & Turf hat leider nichts mehr ...   \n",
       "41                   Der Besuch bleibt in Erinnerung.   \n",
       "51  Wir waren jetzt schon zum 4 Mal hier im August...   \n",
       "57  Eine normale Unterhaltung ist aufgrund der Lau...   \n",
       "67  Die Bedienung hatte wenig Lächeln übrig, war d...   \n",
       "\n",
       "                                               labels  \\\n",
       "id                                                      \n",
       "5   [(GENERAL-IMPRESSION, POSITIVE), (PRICE, NEUTR...   \n",
       "7                    [(GENERAL-IMPRESSION, POSITIVE)]   \n",
       "11                                 [(FOOD, NEGATIVE)]   \n",
       "17                                 [(FOOD, POSITIVE)]   \n",
       "26               [(FOOD, NEGATIVE), (FOOD, NEGATIVE)]   \n",
       "36                   [(GENERAL-IMPRESSION, NEGATIVE)]   \n",
       "41                   [(GENERAL-IMPRESSION, POSITIVE)]   \n",
       "51                   [(GENERAL-IMPRESSION, POSITIVE)]   \n",
       "57                             [(AMBIENCE, NEGATIVE)]   \n",
       "67                              [(SERVICE, NEGATIVE)]   \n",
       "\n",
       "                                       labels_phrases  \\\n",
       "id                                                      \n",
       "5   [(GENERAL-IMPRESSION, POSITIVE, \"NULL\"), (PRIC...   \n",
       "7            [(GENERAL-IMPRESSION, POSITIVE, \"NULL\")]   \n",
       "11                         [(FOOD, NEGATIVE, \"Wein\")]   \n",
       "17                    [(FOOD, POSITIVE, \"Vorspeise\")]   \n",
       "26  [(FOOD, NEGATIVE, \"Beilagensalat\"), (FOOD, NEG...   \n",
       "36    [(GENERAL-IMPRESSION, NEGATIVE, \"Thai & Turf\")]   \n",
       "41           [(GENERAL-IMPRESSION, POSITIVE, \"NULL\")]   \n",
       "51     [(GENERAL-IMPRESSION, POSITIVE, \"Augustiner\")]   \n",
       "57               [(AMBIENCE, NEGATIVE, \"Lautstärke\")]   \n",
       "67                 [(SERVICE, NEGATIVE, \"Bedienung\")]   \n",
       "\n",
       "                                          25shot_rand  \\\n",
       "id                                                      \n",
       "5   [15, 1298, 2058, 746, 822, 402, 771, 1023, 203...   \n",
       "7   [28, 2141, 419, 1949, 457, 831, 109, 741, 3, 3...   \n",
       "11  [333, 37, 1720, 1643, 1454, 708, 663, 1381, 27...   \n",
       "17  [1584, 1737, 510, 756, 1172, 732, 1472, 1567, ...   \n",
       "26  [1398, 1584, 334, 2068, 1988, 685, 793, 1544, ...   \n",
       "36  [178, 1493, 377, 1890, 1063, 381, 88, 1240, 21...   \n",
       "41  [1428, 1625, 816, 1367, 1334, 465, 362, 1813, ...   \n",
       "51  [1854, 1338, 683, 454, 944, 102, 625, 2130, 25...   \n",
       "57  [65, 2073, 2076, 602, 683, 1922, 9, 997, 669, ...   \n",
       "67  [1298, 740, 1976, 387, 276, 1446, 1237, 1664, ...   \n",
       "\n",
       "                                          10shot_rand  \\\n",
       "id                                                      \n",
       "5   [74, 602, 1328, 531, 3, 1988, 1929, 419, 1505,...   \n",
       "7   [874, 640, 1962, 178, 2039, 873, 889, 739, 871...   \n",
       "11  [54, 1414, 1138, 1374, 1852, 1262, 670, 1161, ...   \n",
       "17  [2133, 978, 363, 1427, 1001, 1901, 1015, 199, ...   \n",
       "26  [158, 759, 728, 382, 578, 389, 1880, 592, 379,...   \n",
       "36  [1875, 832, 745, 1128, 1160, 681, 994, 1781, 6...   \n",
       "41  [1281, 1155, 2047, 1636, 1372, 2115, 1832, 194...   \n",
       "51  [839, 1676, 1734, 1942, 125, 114, 1077, 1916, ...   \n",
       "57  [1905, 229, 419, 1231, 765, 1042, 49, 1839, 13...   \n",
       "67  [1347, 1467, 35, 1117, 338, 1987, 1536, 757, 8...   \n",
       "\n",
       "                       5shot_rand  \\\n",
       "id                                  \n",
       "5   [1483, 389, 1132, 1702, 1277]   \n",
       "7    [2075, 1122, 1192, 945, 695]   \n",
       "11     [1766, 728, 568, 49, 1731]   \n",
       "17    [587, 1745, 1089, 901, 506]   \n",
       "26   [1887, 641, 1824, 1586, 517]   \n",
       "36    [1807, 820, 226, 842, 1047]   \n",
       "41     [842, 733, 1658, 725, 916]   \n",
       "51     [676, 1804, 154, 453, 158]   \n",
       "57    [1337, 1597, 950, 447, 830]   \n",
       "67   [1560, 588, 2043, 691, 1277]   \n",
       "\n",
       "                                           25shot_asp  \\\n",
       "id                                                      \n",
       "5   [1365, 1371, 523, 954, 391, 1532, 98, 1176, 94...   \n",
       "7   [1143, 656, 952, 712, 1467, 773, 545, 1294, 98...   \n",
       "11  [1824, 2081, 1983, 847, 1047, 39, 1052, 995, 1...   \n",
       "17  [1583, 27, 1357, 1449, 1456, 1824, 898, 646, 1...   \n",
       "26  [1637, 1975, 119, 765, 578, 1029, 1807, 231, 1...   \n",
       "36  [263, 1475, 2023, 37, 2122, 729, 676, 2079, 14...   \n",
       "41  [73, 195, 1635, 1768, 983, 1176, 211, 1877, 15...   \n",
       "51  [1273, 1362, 722, 1242, 1503, 1227, 1847, 1570...   \n",
       "57  [1893, 736, 1566, 968, 64, 1768, 552, 581, 108...   \n",
       "67  [1059, 502, 1053, 866, 1875, 1104, 1047, 570, ...   \n",
       "\n",
       "                                           10shot_asp  \\\n",
       "id                                                      \n",
       "5   [1056, 1949, 1652, 1524, 1131, 1901, 1780, 863...   \n",
       "7   [1382, 447, 1904, 635, 1118, 380, 767, 56, 166...   \n",
       "11  [1324, 1391, 1170, 373, 1615, 1407, 1470, 1897...   \n",
       "17  [729, 1972, 718, 381, 1274, 2108, 1353, 1853, ...   \n",
       "26  [1672, 1648, 1802, 1618, 1241, 809, 211, 1737,...   \n",
       "36  [1783, 1704, 1909, 1368, 2066, 1868, 1691, 969...   \n",
       "41  [725, 928, 1548, 1225, 147, 208, 1476, 1116, 7...   \n",
       "51  [830, 1750, 637, 1176, 2020, 1522, 85, 44, 124...   \n",
       "57  [1531, 1655, 2106, 1609, 629, 44, 833, 1136, 7...   \n",
       "67  [1487, 1691, 495, 1707, 541, 4, 1368, 670, 141...   \n",
       "\n",
       "                        5shot_asp  \n",
       "id                                 \n",
       "5   [1628, 1797, 533, 1115, 1339]  \n",
       "7    [1780, 119, 2122, 883, 1373]  \n",
       "11   [1710, 1087, 686, 712, 1844]  \n",
       "17    [973, 484, 1177, 1082, 250]  \n",
       "26    [1341, 578, 27, 1092, 1107]  \n",
       "36     [819, 815, 934, 455, 1130]  \n",
       "41     [533, 903, 769, 111, 1709]  \n",
       "51   [990, 1458, 1029, 1394, 277]  \n",
       "57    [186, 602, 2063, 277, 1826]  \n",
       "67   [1451, 574, 1423, 1068, 675]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload  # Python 3.4+\n",
    "\n",
    "import utils.preprocessing\n",
    "reload(utils.preprocessing)\n",
    "import utils.preprocessing\n",
    "from utils.preprocessing import loadDataset, createPrompts\n",
    "\n",
    "\n",
    "args = lambda: None\n",
    "args.lang = \"en\"\n",
    "args.prompt_style = \"short\"\n",
    "args.dataset = 'GERestaurant'\n",
    "args.task = 'e2e'\n",
    "\n",
    "df_train, df_test, label_space = loadDataset(args.dataset, 0, 0)\n",
    "display(df_test.head(10))\n",
    "dataset_train, dataset_test, ground_truth_labels = createPrompts(df_train, df_test, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5c2a2508-6104-4010-9588-40b950b5da4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "You are an advanced AI for text classification, specialized in aspect-based sentiment analysis for texts in English. Extract all (aspect, sentiment, aspect phrase) triples of a sentence by identifying all the addressed aspect categories (AMBIENCE#GENERAL, DRINKS#PRICES, DRINKS#QUALITY, DRINKS#STYLE_OPTIONS, FOOD#PRICES, FOOD#QUALITY, FOOD#STYLE_OPTIONS, LOCATION#GENERAL, SERVICE#GENERAL, RESTAURANT#GENERAL, RESTAURANT#PRICES, RESTAURANT#MISCELLANEOUS) and their corresponding phrases and analyzing the sentiment [POSITIVE, NEUTRAL, NEGATIVE] expressed towards each aspect. Return a list of triples, each containing three strings in parentheses. If an aspect is implied but not explicitly stated, identify its aspect category and sentiment and assign the aspect phrase \"NULL\".\n",
      "\n",
      "### Input:\n",
      "Saul is the best restaurant on Smith Street and in Brooklyn. \n",
      "\n",
      "### Output:\n",
      "[(RESTAURANT#GENERAL, POSITIVE, \"Saul\")]\n",
      "[(FOOD#QUALITY, NEUTRAL, \"food\")]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[5])\n",
    "print(ground_truth_labels[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83eac9e-8b5e-474a-9b8e-0f1aba9411ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m cot \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLets do this step by step. We would like to extract all aspect-sentiment-phrase-triples from the following sentence: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBedienung sehr nett, sehr kompetent, ambienete top, essen top, das Bier überragend, nur zu empfehlen … wir kommen wieder!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. First, we identify all aspects addressed in the sentence and their corresponding phrases: The aspect SERVICE is referenced with the phrase \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBedienung\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, the aspect AMBIENCE is referenced with the phrase \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mambienete\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, the aspect FOOD is referenced with the phrase \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124messen\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and the aspect FOOD is referenced with the phrase \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBier\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. The aspects GENERAL-IMPRESSION and FOOD are inferred from the context of the sentence and are therefore referenced without a phrase. We thus assign the phrases \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNULL\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to both aspects. Next, we determine the sentiment expressed towards these aspects: The aspect SERVICE is mentioned positively, the aspect AMBIENCE is mentioned positively, the aspect FOOD is mentioned positively, the aspect FOOD is mentioned positively, the aspect GENERAL-IMPRESSION is mentioned positively and the aspect FOOD is mentioned positively in the text. The final result thus consists of the following aspect-sentiment-phrase-triples: [(SERVICE, POSITIVE, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBedienung\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m), (AMBIENCE, POSITIVE, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mambienete\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m), (FOOD, POSITIVE, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124messen\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m), (FOOD, POSITIVE, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBier\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m), (GENERAL-IMPRESSION, POSITIVE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(extractAspects(acd, 'acd'))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(extractAspects(acsa, 'acsa'))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# print(extractAspects(cot, 'acsa'))\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(extractAspects(e2e, 'e2e'))\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mextractAspects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macsd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/shared/notebooks/Finetune LLMs/public/scripts/utils/evaluation.py:110\u001b[0m, in \u001b[0;36mextractAspects\u001b[0;34m(output, task, cot, evaluation)\u001b[0m\n\u001b[1;32m    108\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    109\u001b[0m pattern_targets \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(safe_recursive_pattern(\u001b[38;5;241m0\u001b[39m, max_depth))\n\u001b[0;32m--> 110\u001b[0m pairs \u001b[38;5;241m=\u001b[39m \u001b[43mpattern_targets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m pattern_asp \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(REGEX_ASPECTS_ACSD)\n\u001b[1;32m    113\u001b[0m pattern_pol \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(REGEX_LABELS_ACSD)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload  # Python 3.4+\n",
    "\n",
    "import utils.evaluation\n",
    "reload(utils.evaluation)\n",
    "import utils.evaluation\n",
    "from utils.evaluation import extractAspects, convertLabels\n",
    "\n",
    "acd = '[SERVICE, SERVICE, SERVICE]'\n",
    "acsa = '[(GENERAL-IMPRESSION, NEGATIVE)]'\n",
    "e2e = ' [(\"Bedienung\", NEGATIVE), (\"Pizza\", NEGATIVE)].\\n\\n ### Output:\\nLets do this step by step. We would like to extract all opinion-target-phrase-sentiment-tuples from the following sentence: \"Die Tische sind so unglaublich eng aneinander gestellt, dass man kaum Platz zum Atmen hat, die Bedienung war unfreundlich und unflexibel (auf die Frage, ob weniger Käse auf der Pizza möglich wäre, gab\\'s nur'\n",
    "acsd = '[(FOOD#QUALITY, POSITIVE, \"spicy tuna roll\"), (FOOD#QUALITY, POSITIVE, \"rock shrimp tempura\")] '\n",
    "\n",
    "cot = 'Lets do this step by step. We would like to extract all aspect-sentiment-phrase-triples from the following sentence: \"Bedienung sehr nett, sehr kompetent, ambienete top, essen top, das Bier überragend, nur zu empfehlen … wir kommen wieder!\". First, we identify all aspects addressed in the sentence and their corresponding phrases: The aspect SERVICE is referenced with the phrase \"Bedienung\", the aspect AMBIENCE is referenced with the phrase \"ambienete\", the aspect FOOD is referenced with the phrase \"essen\" and the aspect FOOD is referenced with the phrase \"Bier\". The aspects GENERAL-IMPRESSION and FOOD are inferred from the context of the sentence and are therefore referenced without a phrase. We thus assign the phrases \"NULL\" to both aspects. Next, we determine the sentiment expressed towards these aspects: The aspect SERVICE is mentioned positively, the aspect AMBIENCE is mentioned positively, the aspect FOOD is mentioned positively, the aspect FOOD is mentioned positively, the aspect GENERAL-IMPRESSION is mentioned positively and the aspect FOOD is mentioned positively in the text. The final result thus consists of the following aspect-sentiment-phrase-triples: [(SERVICE, POSITIVE, \"Bedienung\"), (AMBIENCE, POSITIVE, \"ambienete\"), (FOOD, POSITIVE, \"essen\"), (FOOD, POSITIVE, \"Bier\"), (GENERAL-IMPRESSION, POSITIVE'\n",
    "# print(extractAspects(acd, 'acd'))\n",
    "# print(extractAspects(acsa, 'acsa'))\n",
    "# print(extractAspects(cot, 'acsa'))\n",
    "# print(extractAspects(e2e, 'e2e'))\n",
    "print(extractAspects(cot, 'acsd', True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01bbbb70-3ff7-41be-bef2-bb4ebd6c47b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_valid_tuples(text):\n",
    "    # Define the pattern for a well-formed tuple: (\"Phrase\", Label)\n",
    "    pattern = r'\\(\\s*\"([^\"]*)\"\\s*,\\s*(POSITIVE|NEGATIVE|NEUTRAL)\\s*\\)'\n",
    "    \n",
    "    # Compile the regex to extract valid tuples\n",
    "    compiled_pattern = re.compile(pattern)\n",
    "    \n",
    "    # Extract all matches from the string\n",
    "    valid_tuples = compiled_pattern.findall(text)\n",
    "    \n",
    "    # Return the tuples in the format [('Phrase', 'Label'), ...]\n",
    "    return valid_tuples\n",
    "\n",
    "# Test case with valid and invalid tuples\n",
    "text = '[(\"Bier (Essen)\", POSITIVE], (\"Köbes (Essen\", POSITIVE, \"Außengastronomie\", POSITIVE)]'\n",
    "\n",
    "# Extract valid tuples\n",
    "valid_tuples = extract_valid_tuples(text)\n",
    "print(valid_tuples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c2137-3b24-443f-975e-8c0389e5e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import utils.evaluation\n",
    "reload(utils.evaluation)\n",
    "import utils.evaluation\n",
    "\n",
    "from utils.evaluation import extractAspects, convertLabels, createResults\n",
    "from ast import literal_eval\n",
    "\n",
    "with open('../results_final/en_GERestaurant__short_e2e_3e-05_8_16_0.05_4_0_full_meta-llama-Meta-Llama-3-8B_en__short_e2e_16_10/predictions.txt') as f:\n",
    "    model_outputs1 = [line for line in f]\n",
    "\n",
    "method1 = []\n",
    "\n",
    "args = lambda: None\n",
    "args.lang = \"en\"\n",
    "args.prompt_style = \"short\"\n",
    "args.dataset = 'GERestaurant'\n",
    "args.task = 'e2e'\n",
    "\n",
    "df_train, df_test, label_space = loadDataset(args.dataset, 0, 0)\n",
    "dataset_train, dataset_test, ground_truth_labels = createPrompts(df_train, df_test, args)\n",
    "\n",
    "ground_truth = []\n",
    "\n",
    "for gt in ground_truth_labels:\n",
    "    ground_truth.append(extractAspects(gt, 'e2e', False, False))\n",
    "    \n",
    "print(ground_truth[0])\n",
    "\n",
    "for out in model_outputs1:\n",
    "    method1.append(extractAspects(out, 'e2e', 'short', True))\n",
    "\n",
    "gold_labels, _ = convertLabels(ground_truth, 'e2e', label_space)\n",
    "pred_labels1, false_predictions1 = convertLabels(method1, 'e2e', label_space)\n",
    "\n",
    "pd.DataFrame([(gold_labels[i], pred_labels1[i]) for i in range(0, len(gold_labels))], columns = ['gt', 'prediction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f5db8a0c-3b19-475f-9d5c-8d24e800f9e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bstrap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbstrap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bootstrap, boostrapping_CI\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 1. implement metric\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_f1\u001b[39m(data):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bstrap'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from bstrap import bootstrap, boostrapping_CI\n",
    "\n",
    "# 1. implement metric\n",
    "def compute_f1(data):\n",
    "    results_asp, results_asp_pol, results_pairs, results_phrases = createResults(data['prediction'], data['gt'], label_space, 'acsd')\n",
    "    return results_phrases['Micro-AVG']['f1']\n",
    "    \n",
    "metric = compute_f1\n",
    "\n",
    "# 4. compare method 1 and 2 (same code as example 1)\n",
    "stats_method1, stats_method2, p_value = bootstrap(metric, method1, method2, nbr_runs=200)\n",
    "print(stats_method1)\n",
    "print(stats_method2)\n",
    "print(p_value)\n",
    "\n",
    "# compute CI and mean for each method separately (same code as example 1)\n",
    "stats_method1 = boostrapping_CI(metric, method1, nbr_runs=200)\n",
    "stats_method2 = boostrapping_CI(metric, method2, nbr_runs=200)\n",
    "print(stats_method1)\n",
    "print(stats_method2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30779dfc-27f4-4a3d-b4c2-25bb09369d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_space = ['AMBIENCE#GENERAL:POSITIVE', 'AMBIENCE#GENERAL:NEUTRAL', 'AMBIENCE#GENERAL:NEGATIVE', 'DRINKS#PRICES:POSITIVE', 'DRINKS#PRICES:NEUTRAL', 'DRINKS#PRICES:NEGATIVE', 'DRINKS#QUALITY:POSITIVE', 'DRINKS#QUALITY:NEUTRAL', 'DRINKS#QUALITY:NEGATIVE', 'DRINKS#STYLE_OPTIONS:POSITIVE', 'DRINKS#STYLE_OPTIONS:NEUTRAL', 'DRINKS#STYLE_OPTIONS:NEGATIVE', 'FOOD#PRICES:POSITIVE', 'FOOD#PRICES:NEUTRAL', 'FOOD#PRICES:NEGATIVE', 'FOOD#QUALITY:POSITIVE', 'FOOD#QUALITY:NEUTRAL', 'FOOD#QUALITY:NEGATIVE', 'FOOD#STYLE_OPTIONS:POSITIVE', 'FOOD#STYLE_OPTIONS:NEUTRAL', 'FOOD#STYLE_OPTIONS:NEGATIVE', 'LOCATION#GENERAL:POSITIVE', 'LOCATION#GENERAL:NEUTRAL', 'LOCATION#GENERAL:NEGATIVE', 'RESTAURANT#GENERAL:POSITIVE', 'RESTAURANT#GENERAL:NEUTRAL', 'RESTAURANT#GENERAL:NEGATIVE', 'RESTAURANT#MISCELLANEOUS:POSITIVE', 'RESTAURANT#MISCELLANEOUS:NEUTRAL', 'RESTAURANT#MISCELLANEOUS:NEGATIVE', 'RESTAURANT#PRICES:POSITIVE', 'RESTAURANT#PRICES:NEUTRAL', 'RESTAURANT#PRICES:NEGATIVE', 'SERVICE#GENERAL:POSITIVE', 'SERVICE#GENERAL:NEUTRAL', 'SERVICE#GENERAL:NEGATIVE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b65f2f-1d66-42da-ba24-78461eeb9acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES'], ['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES'], ['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES']]\n",
      "['[]', '[]', '[]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES'],\n",
       "  ['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES'],\n",
       "  ['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES']],\n",
       " ['[]', '[]', '[]'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import utils.evaluation\n",
    "from utils.evaluation import extractAspects, convertLabels\n",
    "reload(utils.evaluation)\n",
    "\n",
    "from utils.evaluation import extractAspects, convertLabels\n",
    "input_string = [['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES'], ['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES'], ['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES']]\n",
    "\n",
    "convertLabels(input_string, 'acd', label_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bcd01db3-93d7-442c-afb9-16455c3f8ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMBIENCE#GENERAL', 'FOOD#QUALITY', 'RESTAURANT#PRICES']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4430e45a-eaf5-44b7-8ba4-d995635de243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term 1: Red Apple, Term 2: red, Term 3: taste\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Your sentence\n",
    "sentence = \"Red Apple is red, because taste is good.\"\n",
    "\n",
    "# Regular expression pattern\n",
    "pattern = r\"(.*) is (.*), because (.*) is (.*).\"\n",
    "\n",
    "# Use re.match() to match the pattern\n",
    "match = re.match(pattern, sentence)\n",
    "\n",
    "if match:\n",
    "    # Extract the groups\n",
    "    term1 = match.group(1)\n",
    "    term2 = match.group(2)\n",
    "    term3 = match.group(3)\n",
    "    \n",
    "    print(f\"Term 1: {term1}, Term 2: {term2}, Term 3: {term3}\")\n",
    "else:\n",
    "    print(\"No match found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a6ab90a0-2137-4b05-92e1-7ef276693dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teststatistik: 0.0\n",
      "p-Wert: 0.0625\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Daten\n",
    "f1_method_1 = [75, 76, 78, 74, 80]\n",
    "f1_method_2 = [73, 75, 77, 70, 75]\n",
    "\n",
    "# Wilcoxon Signed-Rank Test\n",
    "stat, p_value = stats.wilcoxon(f1_method_1, f1_method_2)\n",
    "\n",
    "print('Teststatistik:', stat)\n",
    "print('p-Wert:', p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e54505f5-7b4b-4d6c-8d84-32f170ede41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teststatistik: 0.866835872224429\n",
      "p-Wert: 0.2538464637612434\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Differenzen berechnen\n",
    "differences = [2, 1, 1, 4, 5]\n",
    "\n",
    "# Shapiro-Wilk-Test\n",
    "stat, p_value = stats.shapiro(differences)\n",
    "\n",
    "print('Teststatistik:', stat)\n",
    "print('p-Wert:', p_value)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Q-Q-Plot\n",
    "stats.probplot(differences, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q-Plot der Differenzen\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f0160a40-fbcf-4607-a9c0-f0725f896471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman Teststatistik: 11.879999999999995\n",
      "Friedman p-Wert: 0.0078057407518306934\n",
      "          0         1         2         3\n",
      "0  1.000000  0.457254  0.900000  0.017331\n",
      "1  0.457254  1.000000  0.457254  0.457254\n",
      "2  0.900000  0.457254  1.000000  0.017331\n",
      "3  0.017331  0.457254  0.017331  1.000000\n"
     ]
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Daten\n",
    "f1_method_1 = [75, 76, 78, 74, 80]\n",
    "f1_method_2 = [73, 75, 77, 70, 75]\n",
    "f1_method_3 = [72, 78, 90, 76, 79]\n",
    "f1_method_4 = [70, 73, 75, 69, 72]\n",
    "\n",
    "# Zusammenführen der Daten in ein DataFrame\n",
    "data = np.array([f1_method_1, f1_method_2, f1_method_3, f1_method_4]).T\n",
    "df = pd.DataFrame(data, columns=['Methode 1', 'Methode 2', 'Methode 3', 'Methode 4'])\n",
    "\n",
    "# Friedman-Test\n",
    "friedman_stat, friedman_p = stats.friedmanchisquare(df['Methode 1'], df['Methode 2'], df['Methode 3'], df['Methode 4'])\n",
    "print('Friedman Teststatistik:', friedman_stat)\n",
    "print('Friedman p-Wert:', friedman_p)\n",
    "\n",
    "# Nemenyi Post-hoc Test\n",
    "nemenyi_results = sp.posthoc_nemenyi_friedman(data)\n",
    "print(nemenyi_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "23c26b3e-6593-4add-b07a-3effc4f3cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ursprüngliche p-Werte: [0.45725382196737474, 0.9, 0.01733064419087016, 0.45725382196737474, 0.4572538219673745, 0.01733064419087016]\n",
      "Korrigierte p-Werte: [1.         1.         0.10398387 1.         1.         0.10398387]\n",
      "Abgelehnte Nullhypothesen (signifikante Unterschiede): [False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Ergebnismatrix der p-Werte\n",
    "p_values_matrix = np.array(nemenyi_results)\n",
    "\n",
    "# Extrahiere die relevanten p-Werte (oberes Dreieck ohne Diagonale)\n",
    "p_values = [\n",
    "    p_values_matrix[0, 1],  # Vergleich Methode 1 vs Methode 2\n",
    "    p_values_matrix[0, 2],  # Vergleich Methode 1 vs Methode 3\n",
    "    p_values_matrix[0, 3],  # Vergleich Methode 1 vs Methode 4\n",
    "    p_values_matrix[1, 2],  # Vergleich Methode 2 vs Methode 3\n",
    "    p_values_matrix[1, 3],  # Vergleich Methode 2 vs Methode 4\n",
    "    p_values_matrix[2, 3]   # Vergleich Methode 3 vs Methode 4\n",
    "]\n",
    "\n",
    "# Holm-Bonferroni-Korrektur\n",
    "corrected_p_values = multipletests(p_values, alpha=0.05, method='holm')\n",
    "\n",
    "print(\"Ursprüngliche p-Werte:\", p_values)\n",
    "print(\"Korrigierte p-Werte:\", corrected_p_values[1])\n",
    "print(\"Abgelehnte Nullhypothesen (signifikante Unterschiede):\", corrected_p_values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "75645a2d-5168-4893-b872-e6bffac8358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman Teststatistik: 22.254193548387093\n",
      "Friedman p-Wert: 0.809513982155323\n",
      "Es gibt keine signifikanten Unterschiede zwischen den Methoden.\n",
      "Nemenyi Post-hoc Test p-Werte:\n",
      "       0    1    2         3         4         5    6    7         8    9  \\\n",
      "0   1.0  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "1   0.9  1.0  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "2   0.9  0.9  1.0  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "3   0.9  0.9  0.9  1.000000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "4   0.9  0.9  0.9  0.900000  1.000000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "5   0.9  0.9  0.9  0.900000  0.900000  1.000000  0.9  0.9  0.900000  0.9   \n",
      "6   0.9  0.9  0.9  0.900000  0.900000  0.900000  1.0  0.9  0.900000  0.9   \n",
      "7   0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  1.0  0.900000  0.9   \n",
      "8   0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  1.000000  0.9   \n",
      "9   0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  1.0   \n",
      "10  0.9  0.9  0.9  0.779551  0.706499  0.828254  0.9  0.9  0.657797  0.9   \n",
      "11  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "12  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "13  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "14  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "15  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "16  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "17  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "18  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "19  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "20  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "21  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "22  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "23  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "24  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "25  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "26  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "27  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "28  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "29  0.9  0.9  0.9  0.900000  0.900000  0.900000  0.9  0.9  0.900000  0.9   \n",
      "\n",
      "          10       11   12   13   14        15   16   17   18        19   20  \\\n",
      "0   0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "1   0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "2   0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "3   0.779551  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "4   0.706499  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "5   0.828254  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "6   0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "7   0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "8   0.657797  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "9   0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "10  1.000000  0.53604  0.9  0.9  0.9  0.779551  0.9  0.9  0.9  0.432895  0.9   \n",
      "11  0.536040  1.00000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "12  0.900000  0.90000  1.0  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "13  0.900000  0.90000  0.9  1.0  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "14  0.900000  0.90000  0.9  0.9  1.0  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "15  0.779551  0.90000  0.9  0.9  0.9  1.000000  0.9  0.9  0.9  0.900000  0.9   \n",
      "16  0.900000  0.90000  0.9  0.9  0.9  0.900000  1.0  0.9  0.9  0.900000  0.9   \n",
      "17  0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  1.0  0.9  0.900000  0.9   \n",
      "18  0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  1.0  0.900000  0.9   \n",
      "19  0.432895  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  1.000000  0.9   \n",
      "20  0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  1.0   \n",
      "21  0.536040  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "22  0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "23  0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "24  0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "25  0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "26  0.803903  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "27  0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "28  0.900000  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "29  0.404004  0.90000  0.9  0.9  0.9  0.900000  0.9  0.9  0.9  0.900000  0.9   \n",
      "\n",
      "         21   22   23   24   25        26   27   28        29  \n",
      "0   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "1   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "2   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "3   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "4   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "5   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "6   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "7   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "8   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "9   0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "10  0.53604  0.9  0.9  0.9  0.9  0.803903  0.9  0.9  0.404004  \n",
      "11  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "12  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "13  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "14  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "15  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "16  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "17  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "18  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "19  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "20  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "21  1.00000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "22  0.90000  1.0  0.9  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "23  0.90000  0.9  1.0  0.9  0.9  0.900000  0.9  0.9  0.900000  \n",
      "24  0.90000  0.9  0.9  1.0  0.9  0.900000  0.9  0.9  0.900000  \n",
      "25  0.90000  0.9  0.9  0.9  1.0  0.900000  0.9  0.9  0.900000  \n",
      "26  0.90000  0.9  0.9  0.9  0.9  1.000000  0.9  0.9  0.900000  \n",
      "27  0.90000  0.9  0.9  0.9  0.9  0.900000  1.0  0.9  0.900000  \n",
      "28  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  1.0  0.900000  \n",
      "29  0.90000  0.9  0.9  0.9  0.9  0.900000  0.9  0.9  1.000000  \n",
      "Signifikante Unterschiede zwischen den Methoden:\n",
      " Empty DataFrame\n",
      "Columns: [Methodenpaar, Ursprünglicher p-Wert, Korrigierter p-Wert, Signifikant]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Beispiel-Daten generieren (30 Methoden, 5 Splits)\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(30, 5) * 100\n",
    "\n",
    "# Daten in ein DataFrame umwandeln\n",
    "methods = [f'Methode {i+1}' for i in range(data.shape[0])]\n",
    "splits = [f'Split {i+1}' for i in range(data.shape[1])]\n",
    "df = pd.DataFrame(data, index=methods, columns=splits)\n",
    "\n",
    "# Friedman-Test\n",
    "friedman_stat, friedman_p = stats.friedmanchisquare(*[df.iloc[i].values for i in range(df.shape[0])])\n",
    "print('Friedman Teststatistik:', friedman_stat)\n",
    "print('Friedman p-Wert:', friedman_p)\n",
    "\n",
    "# Prüfen, ob der Friedman-Test signifikant ist\n",
    "if friedman_p < 0.05:\n",
    "    print(\"Es gibt signifikante Unterschiede zwischen den Methoden.\")\n",
    "else:\n",
    "    print(\"Es gibt keine signifikanten Unterschiede zwischen den Methoden.\")\n",
    "\n",
    "# Nemenyi Post-hoc Test\n",
    "nemenyi_results = sp.posthoc_nemenyi_friedman(df.T.values)\n",
    "print(\"Nemenyi Post-hoc Test p-Werte:\\n\", nemenyi_results)\n",
    "\n",
    "# Holm-Bonferroni-Korrektur\n",
    "# Extrahiere die relevanten p-Werte (oberes Dreieck ohne Diagonale)\n",
    "p_values = []\n",
    "method_pairs = []\n",
    "for i in range(len(methods)):\n",
    "    for j in range(i+1, len(methods)):\n",
    "        p_values.append(nemenyi_results.values[i, j])\n",
    "        method_pairs.append((methods[i], methods[j]))\n",
    "\n",
    "# Holm-Bonferroni-Korrektur anwenden\n",
    "corrected_results = multipletests(p_values, alpha=0.05, method='holm')\n",
    "\n",
    "# Ergebnis in ein DataFrame umwandeln\n",
    "corrected_p_values = corrected_results[1]\n",
    "significant_pairs = corrected_results[0]\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Methodenpaar': method_pairs,\n",
    "    'Ursprünglicher p-Wert': p_values,\n",
    "    'Korrigierter p-Wert': corrected_p_values,\n",
    "    'Signifikant': significant_pairs\n",
    "})\n",
    "\n",
    "# Nur signifikante Paare anzeigen\n",
    "significant_results = results_df[results_df['Signifikant']]\n",
    "print(\"Signifikante Unterschiede zwischen den Methoden:\\n\", significant_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0c9ea811-753c-483b-bf38-723602b38006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman Teststatistik (echte Daten): 11.879999999999995\n",
      "Friedman p-Wert (echte Daten): 0.0078057407518306934\n",
      "Friedman p-Wert (Bootstrapping): 0.000999000999000999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Beispiel-Daten\n",
    "f1_method_1 = [75, 76, 78, 74, 80]\n",
    "f1_method_2 = [73, 75, 77, 70, 75]\n",
    "f1_method_3 = [72, 78, 90, 76, 79]\n",
    "f1_method_4 = [70, 73, 75, 69, 72]\n",
    "\n",
    "# In ein NumPy-Array umwandeln\n",
    "data = np.array([f1_method_1, f1_method_2, f1_method_3, f1_method_4])\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Anzahl der Bootstrap-Iterationen\n",
    "n_bootstraps = 1000\n",
    "\n",
    "# Ergebnisse des Friedman-Tests für die echten Daten\n",
    "friedman_stat, friedman_p = stats.friedmanchisquare(*data)\n",
    "\n",
    "# Bootstrapping\n",
    "bootstrap_stats = []\n",
    "for _ in range(n_bootstraps):\n",
    "    # Resampling mit Ersatz\n",
    "    bootstrap_sample = np.random.choice(data.flatten(), size=data.size, replace=True)\n",
    "    # Reshape zu Originalform\n",
    "    bootstrap_sample = bootstrap_sample.reshape(data.shape)\n",
    "    # Friedman-Test für das Bootstrapped-Sample durchführen\n",
    "    bootstrap_stat, _ = stats.friedmanchisquare(*bootstrap_sample)\n",
    "    bootstrap_stats.append(bootstrap_stat)\n",
    "\n",
    "# Berechne den p-Wert basierend auf den Bootstrapped-Statistiken\n",
    "bootstrap_p_value = (np.sum(np.array(bootstrap_stats) >= friedman_stat) + 1) / (n_bootstraps + 1)\n",
    "\n",
    "print(\"Friedman Teststatistik (echte Daten):\", friedman_stat)\n",
    "print(\"Friedman p-Wert (echte Daten):\", friedman_p)\n",
    "print(\"Friedman p-Wert (Bootstrapping):\", bootstrap_p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "710675d2-dda1-4516-8d4a-49ec6f45daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_full_lin = [0.7589, 0.7717, 0.7754, 0.7462, 0.7590]\n",
    "cond_1000_lin = [0.6881, 0.6982, 0.6676, 0.6899, 0.6961]\n",
    "cond_500_lin = [0.5810, 0.5854, 0.6077, 0.5857, 0.5689]\n",
    "cond_full_cos = [0.7497, 0.7562, 0.7658, 0.7327, 0.7462]\n",
    "cond_1000_cos = [0.6492, 0.6724, 0.6383, 0.6400, 0.6596]\n",
    "cond_500_cos = [0.5413, 0.5722, 0.5729, 0.5696, 0.5560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "44ffcc48-7251-4107-9bd5-0202de9d44a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teststatistik: 0.0\n",
      "p-Wert: 0.0625\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Wilcoxon Signed-Rank Test\n",
    "stat, p_value = stats.wilcoxon(cond_500_lin, cond_500_cos)\n",
    "\n",
    "print('Teststatistik:', stat)\n",
    "print('p-Wert:', p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bbdbbef7-6d85-4da3-906a-57fbcf87647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teststatistik: 0.7994174485077481\n",
      "p-Wert: 0.08015268243255552\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Differenzen berechnen\n",
    "differences = [a - cond_500_cos[i] for i, a in enumerate(cond_500_lin)]\n",
    "\n",
    "# Shapiro-Wilk-Test\n",
    "stat, p_value = stats.shapiro(differences)\n",
    "\n",
    "print('Teststatistik:', stat)\n",
    "print('p-Wert:', p_value)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Q-Q-Plot\n",
    "stats.probplot(differences, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q-Plot der Differenzen\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e8a3e5fd-8d2b-4712-bb75-8452f3964c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gepaarter t-Test zwischen Methode 1 und Methode 2\n",
      "t-Statistik: 10.123225702248572\n",
      "p-Wert: 0.0005359675172490571\n"
     ]
    }
   ],
   "source": [
    "# Zusammenführen der Daten in ein DataFrame\n",
    "data = np.array([cond_full_lin, cond_full_cos]).T\n",
    "\n",
    "# Durchführung eines gepaarten t-Tests zwischen Methode 1 und Methode 2\n",
    "t_stat, p_value = stats.ttest_rel(np.array(cond_full_lin), np.array(cond_full_cos))\n",
    "\n",
    "print(\"Gepaarter t-Test zwischen Methode 1 und Methode 2\")\n",
    "print(\"t-Statistik:\", t_stat)\n",
    "print(\"p-Wert:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0afa36d4-8005-40e0-b96c-2e1c9bdaa4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signifikante Unterschiede zwischen den Methoden:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methodenpaar</th>\n",
       "      <th>Ursprünglicher p-Wert</th>\n",
       "      <th>Korrigierter p-Wert</th>\n",
       "      <th>T-Stat:</th>\n",
       "      <th>Signifikant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Full Linear, 1000 Linear)</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>8.330967</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Full Linear, 500 Linear)</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>31.792772</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Full Linear, Full Cosine)</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>10.123226</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Full Linear, 1000 Cosine)</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>15.801505</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Full Linear, 500 Cosine)</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>30.252894</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1000 Linear, 500 Linear)</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>9.046279</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1000 Linear, 1000 Cosine)</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>8.615323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1000 Linear, 500 Cosine)</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>13.856387</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(500 Linear, 500 Cosine)</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.030872</td>\n",
       "      <td>4.053122</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(Full Cosine, 1000 Cosine)</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>12.494383</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(Full Cosine, 500 Cosine)</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>25.538032</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(1000 Cosine, 500 Cosine)</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>10.014294</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Methodenpaar  Ursprünglicher p-Wert  Korrigierter p-Wert  \\\n",
       "0   (Full Linear, 1000 Linear)               0.000567             0.002993   \n",
       "1    (Full Linear, 500 Linear)               0.000003             0.000044   \n",
       "2   (Full Linear, Full Cosine)               0.000268             0.002412   \n",
       "3   (Full Linear, 1000 Cosine)               0.000047             0.000562   \n",
       "4    (Full Linear, 500 Cosine)               0.000004             0.000050   \n",
       "5    (1000 Linear, 500 Linear)               0.000414             0.002896   \n",
       "7   (1000 Linear, 1000 Cosine)               0.000499             0.002993   \n",
       "8    (1000 Linear, 500 Cosine)               0.000079             0.000865   \n",
       "11    (500 Linear, 500 Cosine)               0.007718             0.030872   \n",
       "12  (Full Cosine, 1000 Cosine)               0.000118             0.001180   \n",
       "13   (Full Cosine, 500 Cosine)               0.000007             0.000091   \n",
       "14   (1000 Cosine, 500 Cosine)               0.000279             0.002412   \n",
       "\n",
       "      T-Stat:  Signifikant  \n",
       "0    8.330967         True  \n",
       "1   31.792772         True  \n",
       "2   10.123226         True  \n",
       "3   15.801505         True  \n",
       "4   30.252894         True  \n",
       "5    9.046279         True  \n",
       "7    8.615323         True  \n",
       "8   13.856387         True  \n",
       "11   4.053122         True  \n",
       "12  12.494383         True  \n",
       "13  25.538032         True  \n",
       "14  10.014294         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Beispiel-Daten\n",
    "cond_full_lin = [0.7589, 0.7717, 0.7754, 0.7462, 0.7590]\n",
    "cond_1000_lin = [0.6881, 0.6982, 0.6676, 0.6899, 0.6961]\n",
    "cond_500_lin = [0.5810, 0.5854, 0.6077, 0.5857, 0.5689]\n",
    "cond_full_cos = [0.7497, 0.7562, 0.7658, 0.7327, 0.7462]\n",
    "cond_1000_cos = [0.6492, 0.6724, 0.6383, 0.6400, 0.6596]\n",
    "cond_500_cos = [0.5413, 0.5722, 0.5729, 0.5696, 0.5560]\n",
    "\n",
    "# In ein NumPy-Array umwandeln\n",
    "data = np.array([cond_full_lin, cond_1000_lin, cond_500_lin, cond_full_cos, cond_1000_cos, cond_500_cos])\n",
    "methods = ['Full Linear', '1000 Linear', '500 Linear', 'Full Cosine', '1000 Cosine', '500 Cosine']\n",
    "\n",
    "# Berechnung der paarweisen t-Tests\n",
    "power = []\n",
    "p_values = []\n",
    "method_pairs = []\n",
    "for i in range(len(methods)):\n",
    "    for j in range(i+1, len(methods)):\n",
    "        t_stat, p_value = stats.ttest_rel(data[i], data[j], alternative = 'greater')\n",
    "        power.append(t_stat)\n",
    "        p_values.append(p_value)\n",
    "        method_pairs.append((methods[i], methods[j]))\n",
    "\n",
    "# Holm-Bonferroni-Korrektur anwenden\n",
    "corrected_results = multipletests(p_values, alpha=0.05, method='holm')\n",
    "\n",
    "# Ergebnis in ein DataFrame umwandeln\n",
    "corrected_p_values = corrected_results[1]\n",
    "significant_pairs = corrected_results[0]\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Methodenpaar': method_pairs,\n",
    "    'Ursprünglicher p-Wert': p_values,\n",
    "    'Korrigierter p-Wert': corrected_p_values,\n",
    "    'T-Stat:': power,\n",
    "    'Signifikant': significant_pairs\n",
    "})\n",
    "\n",
    "# Nur signifikante Paare anzeigen\n",
    "significant_results = results_df[results_df['Signifikant']]\n",
    "print(\"Signifikante Unterschiede zwischen den Methoden:\\n\")\n",
    "display(significant_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1b0c8b5f-6018-400e-89f5-77d48221ca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teststatistik: 0.9174631653855385\n",
      "p-Wert: 0.5137083240316237\n"
     ]
    }
   ],
   "source": [
    "# Differenzen berechnen\n",
    "differences = [a - cond_full_cos[i] for i, a in enumerate(cond_full_lin)]\n",
    "\n",
    "# Shapiro-Wilk-Test\n",
    "stat, p_value = stats.shapiro(differences)\n",
    "\n",
    "print('Teststatistik:', stat)\n",
    "print('p-Wert:', p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bed230-f957-4c34-83b9-5e0328b467a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
